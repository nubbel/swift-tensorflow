// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow/python/framework/cpp_shape_inference.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow/python/framework/cpp_shape_inference.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
class CppShapeInferenceResultDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<CppShapeInferenceResult> {
} _CppShapeInferenceResult_default_instance_;
class CppShapeInferenceInputsNeededDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<CppShapeInferenceInputsNeeded> {
} _CppShapeInferenceInputsNeeded_default_instance_;

namespace protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto {


namespace {

::google::protobuf::Metadata file_level_metadata[2];

}  // namespace

const ::google::protobuf::uint32 TableStruct::offsets[] = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult, shape_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult, handle_shape_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceResult, handle_dtype_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceInputsNeeded, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceInputsNeeded, input_tensors_needed_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(CppShapeInferenceInputsNeeded, input_tensors_as_shapes_needed_),
};

static const ::google::protobuf::internal::MigrationSchema schemas[] = {
  { 0, -1, sizeof(CppShapeInferenceResult)},
  { 7, -1, sizeof(CppShapeInferenceInputsNeeded)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&_CppShapeInferenceResult_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&_CppShapeInferenceInputsNeeded_default_instance_),
};

namespace {

void protobuf_AssignDescriptors() {
  AddDescriptors();
  ::google::protobuf::MessageFactory* factory = NULL;
  AssignDescriptors(
      "tensorflow/python/framework/cpp_shape_inference.proto", schemas, file_default_instances, TableStruct::offsets, factory,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 2);
}

}  // namespace

void TableStruct::Shutdown() {
  _CppShapeInferenceResult_default_instance_.Shutdown();
  delete file_level_metadata[0].reflection;
  _CppShapeInferenceInputsNeeded_default_instance_.Shutdown();
  delete file_level_metadata[1].reflection;
}

void TableStruct::InitDefaultsImpl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::internal::InitProtobufDefaults();
  ::tensorflow::protobuf_tensorflow_2fcore_2fframework_2ftypes_2eproto::InitDefaults();
  ::tensorflow::protobuf_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto::InitDefaults();
  _CppShapeInferenceResult_default_instance_.DefaultConstruct();
  _CppShapeInferenceInputsNeeded_default_instance_.DefaultConstruct();
  _CppShapeInferenceResult_default_instance_.get_mutable()->shape_ = const_cast< ::tensorflow::TensorShapeProto*>(
      ::tensorflow::TensorShapeProto::internal_default_instance());
  _CppShapeInferenceResult_default_instance_.get_mutable()->handle_shape_ = const_cast< ::tensorflow::TensorShapeProto*>(
      ::tensorflow::TensorShapeProto::internal_default_instance());
}

void InitDefaults() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &TableStruct::InitDefaultsImpl);
}
void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] = {
      "\n5tensorflow/python/framework/cpp_shape_"
      "inference.proto\022\ntensorflow\032%tensorflow/"
      "core/framework/types.proto\032,tensorflow/c"
      "ore/framework/tensor_shape.proto\"\246\001\n\027Cpp"
      "ShapeInferenceResult\022+\n\005shape\030\001 \001(\0132\034.te"
      "nsorflow.TensorShapeProto\0222\n\014handle_shap"
      "e\030\002 \001(\0132\034.tensorflow.TensorShapeProto\022*\n"
      "\014handle_dtype\030\003 \001(\0162\024.tensorflow.DataTyp"
      "e\"e\n\035CppShapeInferenceInputsNeeded\022\034\n\024in"
      "put_tensors_needed\030\001 \003(\005\022&\n\036input_tensor"
      "s_as_shapes_needed\030\002 \003(\005B\003\370\001\001b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 437);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow/python/framework/cpp_shape_inference.proto", &protobuf_RegisterTypes);
  ::tensorflow::protobuf_tensorflow_2fcore_2fframework_2ftypes_2eproto::AddDescriptors();
  ::tensorflow::protobuf_tensorflow_2fcore_2fframework_2ftensor_5fshape_2eproto::AddDescriptors();
  ::google::protobuf::internal::OnShutdown(&TableStruct::Shutdown);
}

void AddDescriptors() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;

}  // namespace protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto


// ===================================================================

void CppShapeInferenceResult::_slow_mutable_shape() {
  shape_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorShapeProto >(
      GetArenaNoVirtual());
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::_slow_release_shape() {
  if (shape_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::TensorShapeProto* temp = new ::tensorflow::TensorShapeProto(*shape_);
    shape_ = NULL;
    return temp;
  }
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::unsafe_arena_release_shape() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.CppShapeInferenceResult.shape)
  
  ::tensorflow::TensorShapeProto* temp = shape_;
  shape_ = NULL;
  return temp;
}
void CppShapeInferenceResult::_slow_set_allocated_shape(
    ::google::protobuf::Arena* message_arena, ::tensorflow::TensorShapeProto** shape) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*shape) == NULL) {
      message_arena->Own(*shape);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*shape)) {
      ::tensorflow::TensorShapeProto* new_shape = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorShapeProto >(
            message_arena);
      new_shape->CopyFrom(**shape);
      *shape = new_shape;
    }
}
void CppShapeInferenceResult::unsafe_arena_set_allocated_shape(
    ::tensorflow::TensorShapeProto* shape) {
  if (GetArenaNoVirtual() == NULL) {
    delete shape_;
  }
  shape_ = shape;
  if (shape) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.CppShapeInferenceResult.shape)
}
void CppShapeInferenceResult::_slow_mutable_handle_shape() {
  handle_shape_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorShapeProto >(
      GetArenaNoVirtual());
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::_slow_release_handle_shape() {
  if (handle_shape_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::TensorShapeProto* temp = new ::tensorflow::TensorShapeProto(*handle_shape_);
    handle_shape_ = NULL;
    return temp;
  }
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::unsafe_arena_release_handle_shape() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.CppShapeInferenceResult.handle_shape)
  
  ::tensorflow::TensorShapeProto* temp = handle_shape_;
  handle_shape_ = NULL;
  return temp;
}
void CppShapeInferenceResult::_slow_set_allocated_handle_shape(
    ::google::protobuf::Arena* message_arena, ::tensorflow::TensorShapeProto** handle_shape) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*handle_shape) == NULL) {
      message_arena->Own(*handle_shape);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*handle_shape)) {
      ::tensorflow::TensorShapeProto* new_handle_shape = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::TensorShapeProto >(
            message_arena);
      new_handle_shape->CopyFrom(**handle_shape);
      *handle_shape = new_handle_shape;
    }
}
void CppShapeInferenceResult::unsafe_arena_set_allocated_handle_shape(
    ::tensorflow::TensorShapeProto* handle_shape) {
  if (GetArenaNoVirtual() == NULL) {
    delete handle_shape_;
  }
  handle_shape_ = handle_shape;
  if (handle_shape) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.CppShapeInferenceResult.handle_shape)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CppShapeInferenceResult::kShapeFieldNumber;
const int CppShapeInferenceResult::kHandleShapeFieldNumber;
const int CppShapeInferenceResult::kHandleDtypeFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CppShapeInferenceResult::CppShapeInferenceResult()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CppShapeInferenceResult)
}
CppShapeInferenceResult::CppShapeInferenceResult(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::InitDefaults();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.CppShapeInferenceResult)
}
CppShapeInferenceResult::CppShapeInferenceResult(const CppShapeInferenceResult& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_shape()) {
    shape_ = new ::tensorflow::TensorShapeProto(*from.shape_);
  } else {
    shape_ = NULL;
  }
  if (from.has_handle_shape()) {
    handle_shape_ = new ::tensorflow::TensorShapeProto(*from.handle_shape_);
  } else {
    handle_shape_ = NULL;
  }
  handle_dtype_ = from.handle_dtype_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.CppShapeInferenceResult)
}

void CppShapeInferenceResult::SharedCtor() {
  ::memset(&shape_, 0, reinterpret_cast<char*>(&handle_dtype_) -
    reinterpret_cast<char*>(&shape_) + sizeof(handle_dtype_));
  _cached_size_ = 0;
}

CppShapeInferenceResult::~CppShapeInferenceResult() {
  // @@protoc_insertion_point(destructor:tensorflow.CppShapeInferenceResult)
  SharedDtor();
}

void CppShapeInferenceResult::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

  if (this != internal_default_instance()) {
    delete shape_;
  }
  if (this != internal_default_instance()) {
    delete handle_shape_;
  }
}

void CppShapeInferenceResult::ArenaDtor(void* object) {
  CppShapeInferenceResult* _this = reinterpret_cast< CppShapeInferenceResult* >(object);
  (void)_this;
}
void CppShapeInferenceResult::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void CppShapeInferenceResult::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CppShapeInferenceResult::descriptor() {
  protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::file_level_metadata[0].descriptor;
}

const CppShapeInferenceResult& CppShapeInferenceResult::default_instance() {
  protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::InitDefaults();
  return *internal_default_instance();
}

CppShapeInferenceResult* CppShapeInferenceResult::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<CppShapeInferenceResult>(arena);
}

void CppShapeInferenceResult::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CppShapeInferenceResult)
  if (GetArenaNoVirtual() == NULL && shape_ != NULL) {
    delete shape_;
  }
  shape_ = NULL;
  if (GetArenaNoVirtual() == NULL && handle_shape_ != NULL) {
    delete handle_shape_;
  }
  handle_shape_ = NULL;
  handle_dtype_ = 0;
}

bool CppShapeInferenceResult::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CppShapeInferenceResult)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.TensorShapeProto shape = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_shape()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.TensorShapeProto handle_shape = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_handle_shape()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.DataType handle_dtype = 3;
      case 3: {
        if (tag == 24u) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_handle_dtype(static_cast< ::tensorflow::DataType >(value));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CppShapeInferenceResult)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CppShapeInferenceResult)
  return false;
#undef DO_
}

void CppShapeInferenceResult::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CppShapeInferenceResult)
  // .tensorflow.TensorShapeProto shape = 1;
  if (this->has_shape()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->shape_, output);
  }

  // .tensorflow.TensorShapeProto handle_shape = 2;
  if (this->has_handle_shape()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->handle_shape_, output);
  }

  // .tensorflow.DataType handle_dtype = 3;
  if (this->handle_dtype() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      3, this->handle_dtype(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CppShapeInferenceResult)
}

::google::protobuf::uint8* CppShapeInferenceResult::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CppShapeInferenceResult)
  // .tensorflow.TensorShapeProto shape = 1;
  if (this->has_shape()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->shape_, false, target);
  }

  // .tensorflow.TensorShapeProto handle_shape = 2;
  if (this->has_handle_shape()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *this->handle_shape_, false, target);
  }

  // .tensorflow.DataType handle_dtype = 3;
  if (this->handle_dtype() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      3, this->handle_dtype(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CppShapeInferenceResult)
  return target;
}

size_t CppShapeInferenceResult::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CppShapeInferenceResult)
  size_t total_size = 0;

  // .tensorflow.TensorShapeProto shape = 1;
  if (this->has_shape()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->shape_);
  }

  // .tensorflow.TensorShapeProto handle_shape = 2;
  if (this->has_handle_shape()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->handle_shape_);
  }

  // .tensorflow.DataType handle_dtype = 3;
  if (this->handle_dtype() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->handle_dtype());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CppShapeInferenceResult::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CppShapeInferenceResult)
  GOOGLE_DCHECK_NE(&from, this);
  const CppShapeInferenceResult* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const CppShapeInferenceResult>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CppShapeInferenceResult)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CppShapeInferenceResult)
    MergeFrom(*source);
  }
}

void CppShapeInferenceResult::MergeFrom(const CppShapeInferenceResult& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CppShapeInferenceResult)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_shape()) {
    mutable_shape()->::tensorflow::TensorShapeProto::MergeFrom(from.shape());
  }
  if (from.has_handle_shape()) {
    mutable_handle_shape()->::tensorflow::TensorShapeProto::MergeFrom(from.handle_shape());
  }
  if (from.handle_dtype() != 0) {
    set_handle_dtype(from.handle_dtype());
  }
}

void CppShapeInferenceResult::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CppShapeInferenceResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CppShapeInferenceResult::CopyFrom(const CppShapeInferenceResult& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CppShapeInferenceResult)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CppShapeInferenceResult::IsInitialized() const {
  return true;
}

void CppShapeInferenceResult::Swap(CppShapeInferenceResult* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    CppShapeInferenceResult* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void CppShapeInferenceResult::UnsafeArenaSwap(CppShapeInferenceResult* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void CppShapeInferenceResult::InternalSwap(CppShapeInferenceResult* other) {
  std::swap(shape_, other->shape_);
  std::swap(handle_shape_, other->handle_shape_);
  std::swap(handle_dtype_, other->handle_dtype_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CppShapeInferenceResult::GetMetadata() const {
  protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::file_level_metadata[0];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CppShapeInferenceResult

// .tensorflow.TensorShapeProto shape = 1;
bool CppShapeInferenceResult::has_shape() const {
  return this != internal_default_instance() && shape_ != NULL;
}
void CppShapeInferenceResult::clear_shape() {
  if (GetArenaNoVirtual() == NULL && shape_ != NULL) delete shape_;
  shape_ = NULL;
}
const ::tensorflow::TensorShapeProto& CppShapeInferenceResult::shape() const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceResult.shape)
  return shape_ != NULL ? *shape_
                         : *::tensorflow::TensorShapeProto::internal_default_instance();
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::mutable_shape() {
  
  if (shape_ == NULL) {
    _slow_mutable_shape();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.CppShapeInferenceResult.shape)
  return shape_;
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::release_shape() {
  // @@protoc_insertion_point(field_release:tensorflow.CppShapeInferenceResult.shape)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_shape();
  } else {
    ::tensorflow::TensorShapeProto* temp = shape_;
    shape_ = NULL;
    return temp;
  }
}
 void CppShapeInferenceResult::set_allocated_shape(::tensorflow::TensorShapeProto* shape) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete shape_;
  }
  if (shape != NULL) {
    _slow_set_allocated_shape(message_arena, &shape);
  }
  shape_ = shape;
  if (shape) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.CppShapeInferenceResult.shape)
}

// .tensorflow.TensorShapeProto handle_shape = 2;
bool CppShapeInferenceResult::has_handle_shape() const {
  return this != internal_default_instance() && handle_shape_ != NULL;
}
void CppShapeInferenceResult::clear_handle_shape() {
  if (GetArenaNoVirtual() == NULL && handle_shape_ != NULL) delete handle_shape_;
  handle_shape_ = NULL;
}
const ::tensorflow::TensorShapeProto& CppShapeInferenceResult::handle_shape() const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceResult.handle_shape)
  return handle_shape_ != NULL ? *handle_shape_
                         : *::tensorflow::TensorShapeProto::internal_default_instance();
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::mutable_handle_shape() {
  
  if (handle_shape_ == NULL) {
    _slow_mutable_handle_shape();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.CppShapeInferenceResult.handle_shape)
  return handle_shape_;
}
::tensorflow::TensorShapeProto* CppShapeInferenceResult::release_handle_shape() {
  // @@protoc_insertion_point(field_release:tensorflow.CppShapeInferenceResult.handle_shape)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_handle_shape();
  } else {
    ::tensorflow::TensorShapeProto* temp = handle_shape_;
    handle_shape_ = NULL;
    return temp;
  }
}
 void CppShapeInferenceResult::set_allocated_handle_shape(::tensorflow::TensorShapeProto* handle_shape) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete handle_shape_;
  }
  if (handle_shape != NULL) {
    _slow_set_allocated_handle_shape(message_arena, &handle_shape);
  }
  handle_shape_ = handle_shape;
  if (handle_shape) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.CppShapeInferenceResult.handle_shape)
}

// .tensorflow.DataType handle_dtype = 3;
void CppShapeInferenceResult::clear_handle_dtype() {
  handle_dtype_ = 0;
}
::tensorflow::DataType CppShapeInferenceResult::handle_dtype() const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceResult.handle_dtype)
  return static_cast< ::tensorflow::DataType >(handle_dtype_);
}
void CppShapeInferenceResult::set_handle_dtype(::tensorflow::DataType value) {
  
  handle_dtype_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.CppShapeInferenceResult.handle_dtype)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int CppShapeInferenceInputsNeeded::kInputTensorsNeededFieldNumber;
const int CppShapeInferenceInputsNeeded::kInputTensorsAsShapesNeededFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

CppShapeInferenceInputsNeeded::CppShapeInferenceInputsNeeded()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.CppShapeInferenceInputsNeeded)
}
CppShapeInferenceInputsNeeded::CppShapeInferenceInputsNeeded(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  input_tensors_needed_(arena),
  input_tensors_as_shapes_needed_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::InitDefaults();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.CppShapeInferenceInputsNeeded)
}
CppShapeInferenceInputsNeeded::CppShapeInferenceInputsNeeded(const CppShapeInferenceInputsNeeded& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      input_tensors_needed_(from.input_tensors_needed_),
      input_tensors_as_shapes_needed_(from.input_tensors_as_shapes_needed_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.CppShapeInferenceInputsNeeded)
}

void CppShapeInferenceInputsNeeded::SharedCtor() {
  _cached_size_ = 0;
}

CppShapeInferenceInputsNeeded::~CppShapeInferenceInputsNeeded() {
  // @@protoc_insertion_point(destructor:tensorflow.CppShapeInferenceInputsNeeded)
  SharedDtor();
}

void CppShapeInferenceInputsNeeded::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

}

void CppShapeInferenceInputsNeeded::ArenaDtor(void* object) {
  CppShapeInferenceInputsNeeded* _this = reinterpret_cast< CppShapeInferenceInputsNeeded* >(object);
  (void)_this;
}
void CppShapeInferenceInputsNeeded::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void CppShapeInferenceInputsNeeded::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* CppShapeInferenceInputsNeeded::descriptor() {
  protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::file_level_metadata[1].descriptor;
}

const CppShapeInferenceInputsNeeded& CppShapeInferenceInputsNeeded::default_instance() {
  protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::InitDefaults();
  return *internal_default_instance();
}

CppShapeInferenceInputsNeeded* CppShapeInferenceInputsNeeded::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<CppShapeInferenceInputsNeeded>(arena);
}

void CppShapeInferenceInputsNeeded::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.CppShapeInferenceInputsNeeded)
  input_tensors_needed_.Clear();
  input_tensors_as_shapes_needed_.Clear();
}

bool CppShapeInferenceInputsNeeded::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.CppShapeInferenceInputsNeeded)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated int32 input_tensors_needed = 1;
      case 1: {
        if (tag == 10u) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, this->mutable_input_tensors_needed())));
        } else if (tag == 8u) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 1, 10u, input, this->mutable_input_tensors_needed())));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated int32 input_tensors_as_shapes_needed = 2;
      case 2: {
        if (tag == 18u) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 input, this->mutable_input_tensors_as_shapes_needed())));
        } else if (tag == 16u) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int32, ::google::protobuf::internal::WireFormatLite::TYPE_INT32>(
                 1, 18u, input, this->mutable_input_tensors_as_shapes_needed())));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.CppShapeInferenceInputsNeeded)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.CppShapeInferenceInputsNeeded)
  return false;
#undef DO_
}

void CppShapeInferenceInputsNeeded::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.CppShapeInferenceInputsNeeded)
  // repeated int32 input_tensors_needed = 1;
  if (this->input_tensors_needed_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(1, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(_input_tensors_needed_cached_byte_size_);
  }
  for (int i = 0; i < this->input_tensors_needed_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32NoTag(
      this->input_tensors_needed(i), output);
  }

  // repeated int32 input_tensors_as_shapes_needed = 2;
  if (this->input_tensors_as_shapes_needed_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(2, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(_input_tensors_as_shapes_needed_cached_byte_size_);
  }
  for (int i = 0; i < this->input_tensors_as_shapes_needed_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt32NoTag(
      this->input_tensors_as_shapes_needed(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.CppShapeInferenceInputsNeeded)
}

::google::protobuf::uint8* CppShapeInferenceInputsNeeded::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.CppShapeInferenceInputsNeeded)
  // repeated int32 input_tensors_needed = 1;
  if (this->input_tensors_needed_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      1,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
      _input_tensors_needed_cached_byte_size_, target);
  }
  for (int i = 0; i < this->input_tensors_needed_size(); i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt32NoTagToArray(this->input_tensors_needed(i), target);
  }

  // repeated int32 input_tensors_as_shapes_needed = 2;
  if (this->input_tensors_as_shapes_needed_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      2,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
      _input_tensors_as_shapes_needed_cached_byte_size_, target);
  }
  for (int i = 0; i < this->input_tensors_as_shapes_needed_size(); i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt32NoTagToArray(this->input_tensors_as_shapes_needed(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.CppShapeInferenceInputsNeeded)
  return target;
}

size_t CppShapeInferenceInputsNeeded::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.CppShapeInferenceInputsNeeded)
  size_t total_size = 0;

  // repeated int32 input_tensors_needed = 1;
  {
    size_t data_size = ::google::protobuf::internal::WireFormatLite::
      Int32Size(this->input_tensors_needed_);
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(data_size);
    }
    int cached_size = ::google::protobuf::internal::ToCachedSize(data_size);
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _input_tensors_needed_cached_byte_size_ = cached_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  // repeated int32 input_tensors_as_shapes_needed = 2;
  {
    size_t data_size = ::google::protobuf::internal::WireFormatLite::
      Int32Size(this->input_tensors_as_shapes_needed_);
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(data_size);
    }
    int cached_size = ::google::protobuf::internal::ToCachedSize(data_size);
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _input_tensors_as_shapes_needed_cached_byte_size_ = cached_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void CppShapeInferenceInputsNeeded::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.CppShapeInferenceInputsNeeded)
  GOOGLE_DCHECK_NE(&from, this);
  const CppShapeInferenceInputsNeeded* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const CppShapeInferenceInputsNeeded>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.CppShapeInferenceInputsNeeded)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.CppShapeInferenceInputsNeeded)
    MergeFrom(*source);
  }
}

void CppShapeInferenceInputsNeeded::MergeFrom(const CppShapeInferenceInputsNeeded& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.CppShapeInferenceInputsNeeded)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  input_tensors_needed_.MergeFrom(from.input_tensors_needed_);
  input_tensors_as_shapes_needed_.MergeFrom(from.input_tensors_as_shapes_needed_);
}

void CppShapeInferenceInputsNeeded::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.CppShapeInferenceInputsNeeded)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void CppShapeInferenceInputsNeeded::CopyFrom(const CppShapeInferenceInputsNeeded& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.CppShapeInferenceInputsNeeded)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool CppShapeInferenceInputsNeeded::IsInitialized() const {
  return true;
}

void CppShapeInferenceInputsNeeded::Swap(CppShapeInferenceInputsNeeded* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    CppShapeInferenceInputsNeeded* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void CppShapeInferenceInputsNeeded::UnsafeArenaSwap(CppShapeInferenceInputsNeeded* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void CppShapeInferenceInputsNeeded::InternalSwap(CppShapeInferenceInputsNeeded* other) {
  input_tensors_needed_.UnsafeArenaSwap(&other->input_tensors_needed_);
  input_tensors_as_shapes_needed_.UnsafeArenaSwap(&other->input_tensors_as_shapes_needed_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata CppShapeInferenceInputsNeeded::GetMetadata() const {
  protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_2fpython_2fframework_2fcpp_5fshape_5finference_2eproto::file_level_metadata[1];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// CppShapeInferenceInputsNeeded

// repeated int32 input_tensors_needed = 1;
int CppShapeInferenceInputsNeeded::input_tensors_needed_size() const {
  return input_tensors_needed_.size();
}
void CppShapeInferenceInputsNeeded::clear_input_tensors_needed() {
  input_tensors_needed_.Clear();
}
::google::protobuf::int32 CppShapeInferenceInputsNeeded::input_tensors_needed(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
  return input_tensors_needed_.Get(index);
}
void CppShapeInferenceInputsNeeded::set_input_tensors_needed(int index, ::google::protobuf::int32 value) {
  input_tensors_needed_.Set(index, value);
  // @@protoc_insertion_point(field_set:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
}
void CppShapeInferenceInputsNeeded::add_input_tensors_needed(::google::protobuf::int32 value) {
  input_tensors_needed_.Add(value);
  // @@protoc_insertion_point(field_add:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
}
const ::google::protobuf::RepeatedField< ::google::protobuf::int32 >&
CppShapeInferenceInputsNeeded::input_tensors_needed() const {
  // @@protoc_insertion_point(field_list:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
  return input_tensors_needed_;
}
::google::protobuf::RepeatedField< ::google::protobuf::int32 >*
CppShapeInferenceInputsNeeded::mutable_input_tensors_needed() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_needed)
  return &input_tensors_needed_;
}

// repeated int32 input_tensors_as_shapes_needed = 2;
int CppShapeInferenceInputsNeeded::input_tensors_as_shapes_needed_size() const {
  return input_tensors_as_shapes_needed_.size();
}
void CppShapeInferenceInputsNeeded::clear_input_tensors_as_shapes_needed() {
  input_tensors_as_shapes_needed_.Clear();
}
::google::protobuf::int32 CppShapeInferenceInputsNeeded::input_tensors_as_shapes_needed(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
  return input_tensors_as_shapes_needed_.Get(index);
}
void CppShapeInferenceInputsNeeded::set_input_tensors_as_shapes_needed(int index, ::google::protobuf::int32 value) {
  input_tensors_as_shapes_needed_.Set(index, value);
  // @@protoc_insertion_point(field_set:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
}
void CppShapeInferenceInputsNeeded::add_input_tensors_as_shapes_needed(::google::protobuf::int32 value) {
  input_tensors_as_shapes_needed_.Add(value);
  // @@protoc_insertion_point(field_add:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
}
const ::google::protobuf::RepeatedField< ::google::protobuf::int32 >&
CppShapeInferenceInputsNeeded::input_tensors_as_shapes_needed() const {
  // @@protoc_insertion_point(field_list:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
  return input_tensors_as_shapes_needed_;
}
::google::protobuf::RepeatedField< ::google::protobuf::int32 >*
CppShapeInferenceInputsNeeded::mutable_input_tensors_as_shapes_needed() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.CppShapeInferenceInputsNeeded.input_tensors_as_shapes_needed)
  return &input_tensors_as_shapes_needed_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
