// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/config/model_server_config.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow_serving/config/model_server_config.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
namespace serving {
class ModelConfigDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<ModelConfig> {
} _ModelConfig_default_instance_;
class ModelConfigListDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<ModelConfigList> {
} _ModelConfigList_default_instance_;
class ModelServerConfigDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<ModelServerConfig> {
  public:
  const ::tensorflow::serving::ModelConfigList* model_config_list_;
  const ::google::protobuf::Any* custom_model_config_;
} _ModelServerConfig_default_instance_;

namespace protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto {


namespace {

::google::protobuf::Metadata file_level_metadata[3];
const ::google::protobuf::EnumDescriptor* file_level_enum_descriptors[1];

}  // namespace

const ::google::protobuf::uint32 TableStruct::offsets[] = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, name_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, base_path_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, model_type_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, model_platform_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, version_policy_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfig, logging_config_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfigList, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelConfigList, config_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelServerConfig, _internal_metadata_),
  ~0u,  // no _extensions_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelServerConfig, _oneof_case_[0]),
  PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET((&_ModelServerConfig_default_instance_), model_config_list_),
  PROTO2_GENERATED_DEFAULT_ONEOF_FIELD_OFFSET((&_ModelServerConfig_default_instance_), custom_model_config_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ModelServerConfig, config_),
};

static const ::google::protobuf::internal::MigrationSchema schemas[] = {
  { 0, -1, sizeof(ModelConfig)},
  { 10, -1, sizeof(ModelConfigList)},
  { 15, -1, sizeof(ModelServerConfig)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&_ModelConfig_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&_ModelConfigList_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&_ModelServerConfig_default_instance_),
};

namespace {

void protobuf_AssignDescriptors() {
  AddDescriptors();
  ::google::protobuf::MessageFactory* factory = NULL;
  AssignDescriptors(
      "tensorflow_serving/config/model_server_config.proto", schemas, file_default_instances, TableStruct::offsets, factory,
      file_level_metadata, file_level_enum_descriptors, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 3);
}

}  // namespace

void TableStruct::Shutdown() {
  _ModelConfig_default_instance_.Shutdown();
  delete file_level_metadata[0].reflection;
  _ModelConfigList_default_instance_.Shutdown();
  delete file_level_metadata[1].reflection;
  _ModelServerConfig_default_instance_.Shutdown();
  delete file_level_metadata[2].reflection;
}

void TableStruct::InitDefaultsImpl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::internal::InitProtobufDefaults();
  ::google::protobuf::protobuf_google_2fprotobuf_2fany_2eproto::InitDefaults();
  ::tensorflow::serving::protobuf_tensorflow_5fserving_2fconfig_2flogging_5fconfig_2eproto::InitDefaults();
  ::tensorflow::serving::protobuf_tensorflow_5fserving_2fsources_2fstorage_5fpath_2ffile_5fsystem_5fstorage_5fpath_5fsource_2eproto::InitDefaults();
  _ModelConfig_default_instance_.DefaultConstruct();
  _ModelConfigList_default_instance_.DefaultConstruct();
  _ModelServerConfig_default_instance_.DefaultConstruct();
  _ModelConfig_default_instance_.get_mutable()->logging_config_ = const_cast< ::tensorflow::serving::LoggingConfig*>(
      ::tensorflow::serving::LoggingConfig::internal_default_instance());
  _ModelServerConfig_default_instance_.model_config_list_ = const_cast< ::tensorflow::serving::ModelConfigList*>(
      ::tensorflow::serving::ModelConfigList::internal_default_instance());
  _ModelServerConfig_default_instance_.custom_model_config_ = const_cast< ::google::protobuf::Any*>(
      ::google::protobuf::Any::internal_default_instance());
}

void InitDefaults() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &TableStruct::InitDefaultsImpl);
}
void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] = {
      "\n3tensorflow_serving/config/model_server"
      "_config.proto\022\022tensorflow.serving\032\031googl"
      "e/protobuf/any.proto\032.tensorflow_serving"
      "/config/logging_config.proto\032Mtensorflow"
      "_serving/sources/storage_path/file_syste"
      "m_storage_path_source.proto\"\225\002\n\013ModelCon"
      "fig\022\014\n\004name\030\001 \001(\t\022\021\n\tbase_path\030\002 \001(\t\0225\n\n"
      "model_type\030\003 \001(\0162\035.tensorflow.serving.Mo"
      "delTypeB\002\030\001\022\026\n\016model_platform\030\004 \001(\t\022[\n\016v"
      "ersion_policy\030\005 \001(\0162C.tensorflow.serving"
      ".FileSystemStoragePathSourceConfig.Versi"
      "onPolicy\0229\n\016logging_config\030\006 \001(\0132!.tenso"
      "rflow.serving.LoggingConfig\"B\n\017ModelConf"
      "igList\022/\n\006config\030\001 \003(\0132\037.tensorflow.serv"
      "ing.ModelConfig\"\224\001\n\021ModelServerConfig\022@\n"
      "\021model_config_list\030\001 \001(\0132#.tensorflow.se"
      "rving.ModelConfigListH\000\0223\n\023custom_model_"
      "config\030\002 \001(\0132\024.google.protobuf.AnyH\000B\010\n\006"
      "config*N\n\tModelType\022\036\n\026MODEL_TYPE_UNSPEC"
      "IFIED\020\000\032\002\010\001\022\022\n\nTENSORFLOW\020\001\032\002\010\001\022\r\n\005OTHER"
      "\020\002\032\002\010\001B\003\370\001\001b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 819);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/config/model_server_config.proto", &protobuf_RegisterTypes);
  ::google::protobuf::protobuf_google_2fprotobuf_2fany_2eproto::AddDescriptors();
  ::tensorflow::serving::protobuf_tensorflow_5fserving_2fconfig_2flogging_5fconfig_2eproto::AddDescriptors();
  ::tensorflow::serving::protobuf_tensorflow_5fserving_2fsources_2fstorage_5fpath_2ffile_5fsystem_5fstorage_5fpath_5fsource_2eproto::AddDescriptors();
  ::google::protobuf::internal::OnShutdown(&TableStruct::Shutdown);
}

void AddDescriptors() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;

}  // namespace protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto

const ::google::protobuf::EnumDescriptor* ModelType_descriptor() {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::file_level_enum_descriptors[0];
}
bool ModelType_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}


// ===================================================================

void ModelConfig::_slow_mutable_logging_config() {
  logging_config_ = ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::LoggingConfig >(
      GetArenaNoVirtual());
}
::tensorflow::serving::LoggingConfig* ModelConfig::_slow_release_logging_config() {
  if (logging_config_ == NULL) {
    return NULL;
  } else {
    ::tensorflow::serving::LoggingConfig* temp = new ::tensorflow::serving::LoggingConfig(*logging_config_);
    logging_config_ = NULL;
    return temp;
  }
}
::tensorflow::serving::LoggingConfig* ModelConfig::unsafe_arena_release_logging_config() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelConfig.logging_config)
  
  ::tensorflow::serving::LoggingConfig* temp = logging_config_;
  logging_config_ = NULL;
  return temp;
}
void ModelConfig::_slow_set_allocated_logging_config(
    ::google::protobuf::Arena* message_arena, ::tensorflow::serving::LoggingConfig** logging_config) {
    if (message_arena != NULL && 
        ::google::protobuf::Arena::GetArena(*logging_config) == NULL) {
      message_arena->Own(*logging_config);
    } else if (message_arena !=
               ::google::protobuf::Arena::GetArena(*logging_config)) {
      ::tensorflow::serving::LoggingConfig* new_logging_config = 
            ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::LoggingConfig >(
            message_arena);
      new_logging_config->CopyFrom(**logging_config);
      *logging_config = new_logging_config;
    }
}
void ModelConfig::unsafe_arena_set_allocated_logging_config(
    ::tensorflow::serving::LoggingConfig* logging_config) {
  if (GetArenaNoVirtual() == NULL) {
    delete logging_config_;
  }
  logging_config_ = logging_config;
  if (logging_config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelConfig.logging_config)
}
#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ModelConfig::kNameFieldNumber;
const int ModelConfig::kBasePathFieldNumber;
const int ModelConfig::kModelTypeFieldNumber;
const int ModelConfig::kModelPlatformFieldNumber;
const int ModelConfig::kVersionPolicyFieldNumber;
const int ModelConfig::kLoggingConfigFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ModelConfig::ModelConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ModelConfig)
}
ModelConfig::ModelConfig(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::InitDefaults();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ModelConfig)
}
ModelConfig::ModelConfig(const ModelConfig& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  name_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.name().size() > 0) {
    name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.name(),
      GetArenaNoVirtual());
  }
  base_path_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.base_path().size() > 0) {
    base_path_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.base_path(),
      GetArenaNoVirtual());
  }
  model_platform_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.model_platform().size() > 0) {
    model_platform_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.model_platform(),
      GetArenaNoVirtual());
  }
  if (from.has_logging_config()) {
    logging_config_ = new ::tensorflow::serving::LoggingConfig(*from.logging_config_);
  } else {
    logging_config_ = NULL;
  }
  ::memcpy(&model_type_, &from.model_type_,
    reinterpret_cast<char*>(&version_policy_) -
    reinterpret_cast<char*>(&model_type_) + sizeof(version_policy_));
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ModelConfig)
}

void ModelConfig::SharedCtor() {
  name_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  base_path_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  model_platform_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(&logging_config_, 0, reinterpret_cast<char*>(&version_policy_) -
    reinterpret_cast<char*>(&logging_config_) + sizeof(version_policy_));
  _cached_size_ = 0;
}

ModelConfig::~ModelConfig() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ModelConfig)
  SharedDtor();
}

void ModelConfig::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

  name_.Destroy(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), arena);
  base_path_.Destroy(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), arena);
  model_platform_.Destroy(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), arena);
  if (this != internal_default_instance()) {
    delete logging_config_;
  }
}

void ModelConfig::ArenaDtor(void* object) {
  ModelConfig* _this = reinterpret_cast< ModelConfig* >(object);
  (void)_this;
}
void ModelConfig::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ModelConfig::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ModelConfig::descriptor() {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::file_level_metadata[0].descriptor;
}

const ModelConfig& ModelConfig::default_instance() {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::InitDefaults();
  return *internal_default_instance();
}

ModelConfig* ModelConfig::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ModelConfig>(arena);
}

void ModelConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ModelConfig)
  name_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  base_path_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  model_platform_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
  if (GetArenaNoVirtual() == NULL && logging_config_ != NULL) {
    delete logging_config_;
  }
  logging_config_ = NULL;
  ::memset(&model_type_, 0, reinterpret_cast<char*>(&version_policy_) -
    reinterpret_cast<char*>(&model_type_) + sizeof(version_policy_));
}

bool ModelConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ModelConfig)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // string name = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_name()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->name().data(), this->name().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.ModelConfig.name"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // string base_path = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_base_path()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->base_path().data(), this->base_path().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.ModelConfig.base_path"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
      case 3: {
        if (tag == 24u) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_model_type(static_cast< ::tensorflow::serving::ModelType >(value));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // string model_platform = 4;
      case 4: {
        if (tag == 34u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_model_platform()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->model_platform().data(), this->model_platform().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.ModelConfig.model_platform"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.FileSystemStoragePathSourceConfig.VersionPolicy version_policy = 5;
      case 5: {
        if (tag == 40u) {
          int value;
          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   int, ::google::protobuf::internal::WireFormatLite::TYPE_ENUM>(
                 input, &value)));
          set_version_policy(static_cast< ::tensorflow::serving::FileSystemStoragePathSourceConfig_VersionPolicy >(value));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.LoggingConfig logging_config = 6;
      case 6: {
        if (tag == 50u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_logging_config()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ModelConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ModelConfig)
  return false;
#undef DO_
}

void ModelConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ModelConfig)
  // string name = 1;
  if (this->name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.name");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->name(), output);
  }

  // string base_path = 2;
  if (this->base_path().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->base_path().data(), this->base_path().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.base_path");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      2, this->base_path(), output);
  }

  // .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
  if (this->model_type() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      3, this->model_type(), output);
  }

  // string model_platform = 4;
  if (this->model_platform().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->model_platform().data(), this->model_platform().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.model_platform");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      4, this->model_platform(), output);
  }

  // .tensorflow.serving.FileSystemStoragePathSourceConfig.VersionPolicy version_policy = 5;
  if (this->version_policy() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteEnum(
      5, this->version_policy(), output);
  }

  // .tensorflow.serving.LoggingConfig logging_config = 6;
  if (this->has_logging_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      6, *this->logging_config_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ModelConfig)
}

::google::protobuf::uint8* ModelConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ModelConfig)
  // string name = 1;
  if (this->name().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->name().data(), this->name().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.name");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->name(), target);
  }

  // string base_path = 2;
  if (this->base_path().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->base_path().data(), this->base_path().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.base_path");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        2, this->base_path(), target);
  }

  // .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
  if (this->model_type() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      3, this->model_type(), target);
  }

  // string model_platform = 4;
  if (this->model_platform().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->model_platform().data(), this->model_platform().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.ModelConfig.model_platform");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        4, this->model_platform(), target);
  }

  // .tensorflow.serving.FileSystemStoragePathSourceConfig.VersionPolicy version_policy = 5;
  if (this->version_policy() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteEnumToArray(
      5, this->version_policy(), target);
  }

  // .tensorflow.serving.LoggingConfig logging_config = 6;
  if (this->has_logging_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        6, *this->logging_config_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ModelConfig)
  return target;
}

size_t ModelConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ModelConfig)
  size_t total_size = 0;

  // string name = 1;
  if (this->name().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->name());
  }

  // string base_path = 2;
  if (this->base_path().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->base_path());
  }

  // string model_platform = 4;
  if (this->model_platform().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->model_platform());
  }

  // .tensorflow.serving.LoggingConfig logging_config = 6;
  if (this->has_logging_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->logging_config_);
  }

  // .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
  if (this->model_type() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->model_type());
  }

  // .tensorflow.serving.FileSystemStoragePathSourceConfig.VersionPolicy version_policy = 5;
  if (this->version_policy() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::EnumSize(this->version_policy());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ModelConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ModelConfig)
  GOOGLE_DCHECK_NE(&from, this);
  const ModelConfig* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const ModelConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ModelConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ModelConfig)
    MergeFrom(*source);
  }
}

void ModelConfig::MergeFrom(const ModelConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ModelConfig)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.name().size() > 0) {
    set_name(from.name());
  }
  if (from.base_path().size() > 0) {
    set_base_path(from.base_path());
  }
  if (from.model_platform().size() > 0) {
    set_model_platform(from.model_platform());
  }
  if (from.has_logging_config()) {
    mutable_logging_config()->::tensorflow::serving::LoggingConfig::MergeFrom(from.logging_config());
  }
  if (from.model_type() != 0) {
    set_model_type(from.model_type());
  }
  if (from.version_policy() != 0) {
    set_version_policy(from.version_policy());
  }
}

void ModelConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ModelConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ModelConfig::CopyFrom(const ModelConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ModelConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelConfig::IsInitialized() const {
  return true;
}

void ModelConfig::Swap(ModelConfig* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ModelConfig* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void ModelConfig::UnsafeArenaSwap(ModelConfig* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ModelConfig::InternalSwap(ModelConfig* other) {
  name_.Swap(&other->name_);
  base_path_.Swap(&other->base_path_);
  model_platform_.Swap(&other->model_platform_);
  std::swap(logging_config_, other->logging_config_);
  std::swap(model_type_, other->model_type_);
  std::swap(version_policy_, other->version_policy_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ModelConfig::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::file_level_metadata[0];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ModelConfig

// string name = 1;
void ModelConfig::clear_name() {
  name_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
const ::std::string& ModelConfig::name() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.name)
  return name_.Get();
}
void ModelConfig::set_name(const ::std::string& value) {
  
  name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelConfig.name)
}
void ModelConfig::set_name(const char* value) {
  
  name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
              GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.ModelConfig.name)
}
void ModelConfig::set_name(const char* value,
    size_t size) {
  
  name_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size), GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.ModelConfig.name)
}
::std::string* ModelConfig::mutable_name() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfig.name)
  return name_.Mutable(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
::std::string* ModelConfig::release_name() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelConfig.name)
  
  return name_.Release(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
::std::string* ModelConfig::unsafe_arena_release_name() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelConfig.name)
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  
  return name_.UnsafeArenaRelease(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      GetArenaNoVirtual());
}
void ModelConfig::set_allocated_name(::std::string* name) {
  if (name != NULL) {
    
  } else {
    
  }
  name_.SetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), name,
      GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelConfig.name)
}
void ModelConfig::unsafe_arena_set_allocated_name(
    ::std::string* name) {
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  if (name != NULL) {
    
  } else {
    
  }
  name_.UnsafeArenaSetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      name, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelConfig.name)
}

// string base_path = 2;
void ModelConfig::clear_base_path() {
  base_path_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
const ::std::string& ModelConfig::base_path() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.base_path)
  return base_path_.Get();
}
void ModelConfig::set_base_path(const ::std::string& value) {
  
  base_path_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelConfig.base_path)
}
void ModelConfig::set_base_path(const char* value) {
  
  base_path_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
              GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.ModelConfig.base_path)
}
void ModelConfig::set_base_path(const char* value,
    size_t size) {
  
  base_path_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size), GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.ModelConfig.base_path)
}
::std::string* ModelConfig::mutable_base_path() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfig.base_path)
  return base_path_.Mutable(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
::std::string* ModelConfig::release_base_path() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelConfig.base_path)
  
  return base_path_.Release(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
::std::string* ModelConfig::unsafe_arena_release_base_path() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelConfig.base_path)
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  
  return base_path_.UnsafeArenaRelease(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      GetArenaNoVirtual());
}
void ModelConfig::set_allocated_base_path(::std::string* base_path) {
  if (base_path != NULL) {
    
  } else {
    
  }
  base_path_.SetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), base_path,
      GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelConfig.base_path)
}
void ModelConfig::unsafe_arena_set_allocated_base_path(
    ::std::string* base_path) {
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  if (base_path != NULL) {
    
  } else {
    
  }
  base_path_.UnsafeArenaSetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      base_path, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelConfig.base_path)
}

// .tensorflow.serving.ModelType model_type = 3 [deprecated = true];
void ModelConfig::clear_model_type() {
  model_type_ = 0;
}
::tensorflow::serving::ModelType ModelConfig::model_type() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.model_type)
  return static_cast< ::tensorflow::serving::ModelType >(model_type_);
}
void ModelConfig::set_model_type(::tensorflow::serving::ModelType value) {
  
  model_type_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelConfig.model_type)
}

// string model_platform = 4;
void ModelConfig::clear_model_platform() {
  model_platform_.ClearToEmpty(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
const ::std::string& ModelConfig::model_platform() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.model_platform)
  return model_platform_.Get();
}
void ModelConfig::set_model_platform(const ::std::string& value) {
  
  model_platform_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelConfig.model_platform)
}
void ModelConfig::set_model_platform(const char* value) {
  
  model_platform_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value),
              GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.ModelConfig.model_platform)
}
void ModelConfig::set_model_platform(const char* value,
    size_t size) {
  
  model_platform_.Set(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(
      reinterpret_cast<const char*>(value), size), GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.ModelConfig.model_platform)
}
::std::string* ModelConfig::mutable_model_platform() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfig.model_platform)
  return model_platform_.Mutable(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
::std::string* ModelConfig::release_model_platform() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelConfig.model_platform)
  
  return model_platform_.Release(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), GetArenaNoVirtual());
}
::std::string* ModelConfig::unsafe_arena_release_model_platform() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelConfig.model_platform)
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  
  return model_platform_.UnsafeArenaRelease(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      GetArenaNoVirtual());
}
void ModelConfig::set_allocated_model_platform(::std::string* model_platform) {
  if (model_platform != NULL) {
    
  } else {
    
  }
  model_platform_.SetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), model_platform,
      GetArenaNoVirtual());
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelConfig.model_platform)
}
void ModelConfig::unsafe_arena_set_allocated_model_platform(
    ::std::string* model_platform) {
  GOOGLE_DCHECK(GetArenaNoVirtual() != NULL);
  if (model_platform != NULL) {
    
  } else {
    
  }
  model_platform_.UnsafeArenaSetAllocated(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      model_platform, GetArenaNoVirtual());
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelConfig.model_platform)
}

// .tensorflow.serving.FileSystemStoragePathSourceConfig.VersionPolicy version_policy = 5;
void ModelConfig::clear_version_policy() {
  version_policy_ = 0;
}
::tensorflow::serving::FileSystemStoragePathSourceConfig_VersionPolicy ModelConfig::version_policy() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.version_policy)
  return static_cast< ::tensorflow::serving::FileSystemStoragePathSourceConfig_VersionPolicy >(version_policy_);
}
void ModelConfig::set_version_policy(::tensorflow::serving::FileSystemStoragePathSourceConfig_VersionPolicy value) {
  
  version_policy_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.serving.ModelConfig.version_policy)
}

// .tensorflow.serving.LoggingConfig logging_config = 6;
bool ModelConfig::has_logging_config() const {
  return this != internal_default_instance() && logging_config_ != NULL;
}
void ModelConfig::clear_logging_config() {
  if (GetArenaNoVirtual() == NULL && logging_config_ != NULL) delete logging_config_;
  logging_config_ = NULL;
}
const ::tensorflow::serving::LoggingConfig& ModelConfig::logging_config() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfig.logging_config)
  return logging_config_ != NULL ? *logging_config_
                         : *::tensorflow::serving::LoggingConfig::internal_default_instance();
}
::tensorflow::serving::LoggingConfig* ModelConfig::mutable_logging_config() {
  
  if (logging_config_ == NULL) {
    _slow_mutable_logging_config();
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfig.logging_config)
  return logging_config_;
}
::tensorflow::serving::LoggingConfig* ModelConfig::release_logging_config() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelConfig.logging_config)
  
  if (GetArenaNoVirtual() != NULL) {
    return _slow_release_logging_config();
  } else {
    ::tensorflow::serving::LoggingConfig* temp = logging_config_;
    logging_config_ = NULL;
    return temp;
  }
}
 void ModelConfig::set_allocated_logging_config(::tensorflow::serving::LoggingConfig* logging_config) {
  ::google::protobuf::Arena* message_arena = GetArenaNoVirtual();
  if (message_arena == NULL) {
    delete logging_config_;
  }
  if (logging_config != NULL) {
    _slow_set_allocated_logging_config(message_arena, &logging_config);
  }
  logging_config_ = logging_config;
  if (logging_config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelConfig.logging_config)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ModelConfigList::kConfigFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ModelConfigList::ModelConfigList()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ModelConfigList)
}
ModelConfigList::ModelConfigList(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena),
  config_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::InitDefaults();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ModelConfigList)
}
ModelConfigList::ModelConfigList(const ModelConfigList& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      config_(from.config_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ModelConfigList)
}

void ModelConfigList::SharedCtor() {
  _cached_size_ = 0;
}

ModelConfigList::~ModelConfigList() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ModelConfigList)
  SharedDtor();
}

void ModelConfigList::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

}

void ModelConfigList::ArenaDtor(void* object) {
  ModelConfigList* _this = reinterpret_cast< ModelConfigList* >(object);
  (void)_this;
}
void ModelConfigList::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ModelConfigList::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ModelConfigList::descriptor() {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::file_level_metadata[1].descriptor;
}

const ModelConfigList& ModelConfigList::default_instance() {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::InitDefaults();
  return *internal_default_instance();
}

ModelConfigList* ModelConfigList::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ModelConfigList>(arena);
}

void ModelConfigList::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ModelConfigList)
  config_.Clear();
}

bool ModelConfigList::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ModelConfigList)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.serving.ModelConfig config = 1;
      case 1: {
        if (tag == 10u) {
          DO_(input->IncrementRecursionDepth());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_config()));
        } else {
          goto handle_unusual;
        }
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ModelConfigList)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ModelConfigList)
  return false;
#undef DO_
}

void ModelConfigList::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ModelConfigList)
  // repeated .tensorflow.serving.ModelConfig config = 1;
  for (unsigned int i = 0, n = this->config_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->config(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ModelConfigList)
}

::google::protobuf::uint8* ModelConfigList::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ModelConfigList)
  // repeated .tensorflow.serving.ModelConfig config = 1;
  for (unsigned int i = 0, n = this->config_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->config(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ModelConfigList)
  return target;
}

size_t ModelConfigList::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ModelConfigList)
  size_t total_size = 0;

  // repeated .tensorflow.serving.ModelConfig config = 1;
  {
    unsigned int count = this->config_size();
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->config(i));
    }
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ModelConfigList::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ModelConfigList)
  GOOGLE_DCHECK_NE(&from, this);
  const ModelConfigList* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const ModelConfigList>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ModelConfigList)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ModelConfigList)
    MergeFrom(*source);
  }
}

void ModelConfigList::MergeFrom(const ModelConfigList& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ModelConfigList)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  config_.MergeFrom(from.config_);
}

void ModelConfigList::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ModelConfigList)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ModelConfigList::CopyFrom(const ModelConfigList& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ModelConfigList)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelConfigList::IsInitialized() const {
  return true;
}

void ModelConfigList::Swap(ModelConfigList* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ModelConfigList* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void ModelConfigList::UnsafeArenaSwap(ModelConfigList* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ModelConfigList::InternalSwap(ModelConfigList* other) {
  config_.UnsafeArenaSwap(&other->config_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ModelConfigList::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::file_level_metadata[1];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ModelConfigList

// repeated .tensorflow.serving.ModelConfig config = 1;
int ModelConfigList::config_size() const {
  return config_.size();
}
void ModelConfigList::clear_config() {
  config_.Clear();
}
const ::tensorflow::serving::ModelConfig& ModelConfigList::config(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelConfigList.config)
  return config_.Get(index);
}
::tensorflow::serving::ModelConfig* ModelConfigList::mutable_config(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelConfigList.config)
  return config_.Mutable(index);
}
::tensorflow::serving::ModelConfig* ModelConfigList::add_config() {
  // @@protoc_insertion_point(field_add:tensorflow.serving.ModelConfigList.config)
  return config_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::serving::ModelConfig >*
ModelConfigList::mutable_config() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.ModelConfigList.config)
  return &config_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::serving::ModelConfig >&
ModelConfigList::config() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.ModelConfigList.config)
  return config_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ModelServerConfig::kModelConfigListFieldNumber;
const int ModelServerConfig::kCustomModelConfigFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ModelServerConfig::ModelServerConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ModelServerConfig)
}
ModelServerConfig::ModelServerConfig(::google::protobuf::Arena* arena)
  : ::google::protobuf::Message(),
  _internal_metadata_(arena) {
#ifdef GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::InitDefaults();
#endif  // GOOGLE_PROTOBUF_NO_STATIC_INITIALIZER
  SharedCtor();
  RegisterArenaDtor(arena);
  // @@protoc_insertion_point(arena_constructor:tensorflow.serving.ModelServerConfig)
}
ModelServerConfig::ModelServerConfig(const ModelServerConfig& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  clear_has_config();
  switch (from.config_case()) {
    case kModelConfigList: {
      mutable_model_config_list()->::tensorflow::serving::ModelConfigList::MergeFrom(from.model_config_list());
      break;
    }
    case kCustomModelConfig: {
      mutable_custom_model_config()->::google::protobuf::Any::MergeFrom(from.custom_model_config());
      break;
    }
    case CONFIG_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ModelServerConfig)
}

void ModelServerConfig::SharedCtor() {
  clear_has_config();
  _cached_size_ = 0;
}

ModelServerConfig::~ModelServerConfig() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ModelServerConfig)
  SharedDtor();
}

void ModelServerConfig::SharedDtor() {
  ::google::protobuf::Arena* arena = GetArenaNoVirtual();
  if (arena != NULL) {
    return;
  }

  if (has_config()) {
    clear_config();
  }
}

void ModelServerConfig::ArenaDtor(void* object) {
  ModelServerConfig* _this = reinterpret_cast< ModelServerConfig* >(object);
  (void)_this;
}
void ModelServerConfig::RegisterArenaDtor(::google::protobuf::Arena* arena) {
}
void ModelServerConfig::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ModelServerConfig::descriptor() {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::file_level_metadata[2].descriptor;
}

const ModelServerConfig& ModelServerConfig::default_instance() {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::InitDefaults();
  return *internal_default_instance();
}

ModelServerConfig* ModelServerConfig::New(::google::protobuf::Arena* arena) const {
  return ::google::protobuf::Arena::CreateMessage<ModelServerConfig>(arena);
}

void ModelServerConfig::clear_config() {
// @@protoc_insertion_point(one_of_clear_start:tensorflow.serving.ModelServerConfig)
  switch (config_case()) {
    case kModelConfigList: {
      if (GetArenaNoVirtual() == NULL) {
        delete config_.model_config_list_;
      }
      break;
    }
    case kCustomModelConfig: {
      if (GetArenaNoVirtual() == NULL) {
        delete config_.custom_model_config_;
      }
      break;
    }
    case CONFIG_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = CONFIG_NOT_SET;
}


void ModelServerConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ModelServerConfig)
  clear_config();
}

bool ModelServerConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ModelServerConfig)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.ModelConfigList model_config_list = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_model_config_list()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Any custom_model_config = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_custom_model_config()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ModelServerConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ModelServerConfig)
  return false;
#undef DO_
}

void ModelServerConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ModelServerConfig)
  // .tensorflow.serving.ModelConfigList model_config_list = 1;
  if (has_model_config_list()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *config_.model_config_list_, output);
  }

  // .google.protobuf.Any custom_model_config = 2;
  if (has_custom_model_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *config_.custom_model_config_, output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ModelServerConfig)
}

::google::protobuf::uint8* ModelServerConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ModelServerConfig)
  // .tensorflow.serving.ModelConfigList model_config_list = 1;
  if (has_model_config_list()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *config_.model_config_list_, false, target);
  }

  // .google.protobuf.Any custom_model_config = 2;
  if (has_custom_model_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *config_.custom_model_config_, false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ModelServerConfig)
  return target;
}

size_t ModelServerConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ModelServerConfig)
  size_t total_size = 0;

  switch (config_case()) {
    // .tensorflow.serving.ModelConfigList model_config_list = 1;
    case kModelConfigList: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *config_.model_config_list_);
      break;
    }
    // .google.protobuf.Any custom_model_config = 2;
    case kCustomModelConfig: {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          *config_.custom_model_config_);
      break;
    }
    case CONFIG_NOT_SET: {
      break;
    }
  }
  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ModelServerConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ModelServerConfig)
  GOOGLE_DCHECK_NE(&from, this);
  const ModelServerConfig* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const ModelServerConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ModelServerConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ModelServerConfig)
    MergeFrom(*source);
  }
}

void ModelServerConfig::MergeFrom(const ModelServerConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ModelServerConfig)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  switch (from.config_case()) {
    case kModelConfigList: {
      mutable_model_config_list()->::tensorflow::serving::ModelConfigList::MergeFrom(from.model_config_list());
      break;
    }
    case kCustomModelConfig: {
      mutable_custom_model_config()->::google::protobuf::Any::MergeFrom(from.custom_model_config());
      break;
    }
    case CONFIG_NOT_SET: {
      break;
    }
  }
}

void ModelServerConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ModelServerConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ModelServerConfig::CopyFrom(const ModelServerConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ModelServerConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ModelServerConfig::IsInitialized() const {
  return true;
}

void ModelServerConfig::Swap(ModelServerConfig* other) {
  if (other == this) return;
  if (GetArenaNoVirtual() == other->GetArenaNoVirtual()) {
    InternalSwap(other);
  } else {
    ModelServerConfig* temp = New(GetArenaNoVirtual());
    temp->MergeFrom(*other);
    other->CopyFrom(*this);
    InternalSwap(temp);
    if (GetArenaNoVirtual() == NULL) {
      delete temp;
    }
  }
}
void ModelServerConfig::UnsafeArenaSwap(ModelServerConfig* other) {
  if (other == this) return;
  GOOGLE_DCHECK(GetArenaNoVirtual() == other->GetArenaNoVirtual());
  InternalSwap(other);
}
void ModelServerConfig::InternalSwap(ModelServerConfig* other) {
  std::swap(config_, other->config_);
  std::swap(_oneof_case_[0], other->_oneof_case_[0]);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ModelServerConfig::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fconfig_2fmodel_5fserver_5fconfig_2eproto::file_level_metadata[2];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ModelServerConfig

// .tensorflow.serving.ModelConfigList model_config_list = 1;
bool ModelServerConfig::has_model_config_list() const {
  return config_case() == kModelConfigList;
}
void ModelServerConfig::set_has_model_config_list() {
  _oneof_case_[0] = kModelConfigList;
}
void ModelServerConfig::clear_model_config_list() {
  if (has_model_config_list()) {
    if (GetArenaNoVirtual() == NULL) {
      delete config_.model_config_list_;
    }
    clear_has_config();
  }
}
 const ::tensorflow::serving::ModelConfigList& ModelServerConfig::model_config_list() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelServerConfig.model_config_list)
  return has_model_config_list()
      ? *config_.model_config_list_
      : ::tensorflow::serving::ModelConfigList::default_instance();
}
::tensorflow::serving::ModelConfigList* ModelServerConfig::mutable_model_config_list() {
  if (!has_model_config_list()) {
    clear_config();
    set_has_model_config_list();
    config_.model_config_list_ = 
      ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelConfigList >(
      GetArenaNoVirtual());
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelServerConfig.model_config_list)
  return config_.model_config_list_;
}
::tensorflow::serving::ModelConfigList* ModelServerConfig::release_model_config_list() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelServerConfig.model_config_list)
  if (has_model_config_list()) {
    clear_has_config();
    if (GetArenaNoVirtual() != NULL) {
      ::tensorflow::serving::ModelConfigList* temp = new ::tensorflow::serving::ModelConfigList(*config_.model_config_list_);
      config_.model_config_list_ = NULL;
      return temp;
    } else {
      ::tensorflow::serving::ModelConfigList* temp = config_.model_config_list_;
      config_.model_config_list_ = NULL;
      return temp;
    }
  } else {
    return NULL;
  }
}
void ModelServerConfig::set_allocated_model_config_list(::tensorflow::serving::ModelConfigList* model_config_list) {
  clear_config();
  if (model_config_list) {
    if (GetArenaNoVirtual() != NULL &&
        ::google::protobuf::Arena::GetArena(model_config_list) == NULL) {
      GetArenaNoVirtual()->Own(model_config_list);
    } else if (GetArenaNoVirtual() !=
               ::google::protobuf::Arena::GetArena(model_config_list)) {
      ::tensorflow::serving::ModelConfigList* new_model_config_list = 
          ::google::protobuf::Arena::CreateMessage< ::tensorflow::serving::ModelConfigList >(
          GetArenaNoVirtual());
      new_model_config_list->CopyFrom(*model_config_list);
      model_config_list = new_model_config_list;
    }
    set_has_model_config_list();
    config_.model_config_list_ = model_config_list;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelServerConfig.model_config_list)
}
 ::tensorflow::serving::ModelConfigList* ModelServerConfig::unsafe_arena_release_model_config_list() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelServerConfig.model_config_list)
  if (has_model_config_list()) {
    clear_has_config();
    ::tensorflow::serving::ModelConfigList* temp = config_.model_config_list_;
    config_.model_config_list_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
 void ModelServerConfig::unsafe_arena_set_allocated_model_config_list(::tensorflow::serving::ModelConfigList* model_config_list) {
  clear_config();
  if (model_config_list) {
    set_has_model_config_list();
    config_.model_config_list_ = model_config_list;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelServerConfig.model_config_list)
}

// .google.protobuf.Any custom_model_config = 2;
bool ModelServerConfig::has_custom_model_config() const {
  return config_case() == kCustomModelConfig;
}
void ModelServerConfig::set_has_custom_model_config() {
  _oneof_case_[0] = kCustomModelConfig;
}
void ModelServerConfig::clear_custom_model_config() {
  if (has_custom_model_config()) {
    if (GetArenaNoVirtual() == NULL) {
      delete config_.custom_model_config_;
    }
    clear_has_config();
  }
}
 const ::google::protobuf::Any& ModelServerConfig::custom_model_config() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ModelServerConfig.custom_model_config)
  return has_custom_model_config()
      ? *config_.custom_model_config_
      : ::google::protobuf::Any::default_instance();
}
::google::protobuf::Any* ModelServerConfig::mutable_custom_model_config() {
  if (!has_custom_model_config()) {
    clear_config();
    set_has_custom_model_config();
    config_.custom_model_config_ = 
      ::google::protobuf::Arena::Create< ::google::protobuf::Any >(
      GetArenaNoVirtual());
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ModelServerConfig.custom_model_config)
  return config_.custom_model_config_;
}
::google::protobuf::Any* ModelServerConfig::release_custom_model_config() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ModelServerConfig.custom_model_config)
  if (has_custom_model_config()) {
    clear_has_config();
    if (GetArenaNoVirtual() != NULL) {
      ::google::protobuf::Any* temp = new ::google::protobuf::Any(*config_.custom_model_config_);
      config_.custom_model_config_ = NULL;
      return temp;
    } else {
      ::google::protobuf::Any* temp = config_.custom_model_config_;
      config_.custom_model_config_ = NULL;
      return temp;
    }
  } else {
    return NULL;
  }
}
void ModelServerConfig::set_allocated_custom_model_config(::google::protobuf::Any* custom_model_config) {
  clear_config();
  if (custom_model_config) {
    if (GetArenaNoVirtual() != NULL) {
      GetArenaNoVirtual()->Own(custom_model_config);
    }
    set_has_custom_model_config();
    config_.custom_model_config_ = custom_model_config;
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ModelServerConfig.custom_model_config)
}
 ::google::protobuf::Any* ModelServerConfig::unsafe_arena_release_custom_model_config() {
  // @@protoc_insertion_point(field_unsafe_arena_release:tensorflow.serving.ModelServerConfig.custom_model_config)
  if (has_custom_model_config()) {
    clear_has_config();
    ::google::protobuf::Any* temp = config_.custom_model_config_;
    config_.custom_model_config_ = NULL;
    return temp;
  } else {
    return NULL;
  }
}
 void ModelServerConfig::unsafe_arena_set_allocated_custom_model_config(::google::protobuf::Any* custom_model_config) {
  clear_config();
  if (custom_model_config) {
    set_has_custom_model_config();
    config_.custom_model_config_ = custom_model_config;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:tensorflow.serving.ModelServerConfig.custom_model_config)
}

bool ModelServerConfig::has_config() const {
  return config_case() != CONFIG_NOT_SET;
}
void ModelServerConfig::clear_has_config() {
  _oneof_case_[0] = CONFIG_NOT_SET;
}
ModelServerConfig::ConfigCase ModelServerConfig::config_case() const {
  return ModelServerConfig::ConfigCase(_oneof_case_[0]);
}
#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
