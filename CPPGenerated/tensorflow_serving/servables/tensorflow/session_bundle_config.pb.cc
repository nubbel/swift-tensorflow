// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/servables/tensorflow/session_bundle_config.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow_serving/servables/tensorflow/session_bundle_config.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
namespace serving {
class SessionBundleConfigDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<SessionBundleConfig> {
} _SessionBundleConfig_default_instance_;
class BatchingParametersDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<BatchingParameters> {
} _BatchingParameters_default_instance_;

namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto {


namespace {

::google::protobuf::Metadata file_level_metadata[2];

}  // namespace

const ::google::protobuf::uint32 TableStruct::offsets[] = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionBundleConfig, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionBundleConfig, session_target_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionBundleConfig, session_config_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionBundleConfig, batching_parameters_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionBundleConfig, session_run_load_threadpool_index_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(SessionBundleConfig, experimental_fixed_input_tensors_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(BatchingParameters, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(BatchingParameters, max_batch_size_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(BatchingParameters, batch_timeout_micros_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(BatchingParameters, max_enqueued_batches_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(BatchingParameters, num_batch_threads_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(BatchingParameters, thread_pool_name_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(BatchingParameters, allowed_batch_sizes_),
};

static const ::google::protobuf::internal::MigrationSchema schemas[] = {
  { 0, -1, sizeof(SessionBundleConfig)},
  { 9, -1, sizeof(BatchingParameters)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&_SessionBundleConfig_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&_BatchingParameters_default_instance_),
};

namespace {

void protobuf_AssignDescriptors() {
  AddDescriptors();
  ::google::protobuf::MessageFactory* factory = NULL;
  AssignDescriptors(
      "tensorflow_serving/servables/tensorflow/session_bundle_config.proto", schemas, file_default_instances, TableStruct::offsets, factory,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 2);
}

}  // namespace

void TableStruct::Shutdown() {
  _SessionBundleConfig_default_instance_.Shutdown();
  delete file_level_metadata[0].reflection;
  _BatchingParameters_default_instance_.Shutdown();
  delete file_level_metadata[1].reflection;
}

void TableStruct::InitDefaultsImpl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::internal::InitProtobufDefaults();
  ::google::protobuf::protobuf_google_2fprotobuf_2fwrappers_2eproto::InitDefaults();
  ::tensorflow::protobuf_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto::InitDefaults();
  ::tensorflow::protobuf_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto::InitDefaults();
  _SessionBundleConfig_default_instance_.DefaultConstruct();
  _BatchingParameters_default_instance_.DefaultConstruct();
  _SessionBundleConfig_default_instance_.get_mutable()->session_config_ = const_cast< ::tensorflow::ConfigProto*>(
      ::tensorflow::ConfigProto::internal_default_instance());
  _SessionBundleConfig_default_instance_.get_mutable()->batching_parameters_ = const_cast< ::tensorflow::serving::BatchingParameters*>(
      ::tensorflow::serving::BatchingParameters::internal_default_instance());
  _SessionBundleConfig_default_instance_.get_mutable()->session_run_load_threadpool_index_ = const_cast< ::google::protobuf::Int32Value*>(
      ::google::protobuf::Int32Value::internal_default_instance());
  _BatchingParameters_default_instance_.get_mutable()->max_batch_size_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  _BatchingParameters_default_instance_.get_mutable()->batch_timeout_micros_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  _BatchingParameters_default_instance_.get_mutable()->max_enqueued_batches_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  _BatchingParameters_default_instance_.get_mutable()->num_batch_threads_ = const_cast< ::google::protobuf::Int64Value*>(
      ::google::protobuf::Int64Value::internal_default_instance());
  _BatchingParameters_default_instance_.get_mutable()->thread_pool_name_ = const_cast< ::google::protobuf::StringValue*>(
      ::google::protobuf::StringValue::internal_default_instance());
}

void InitDefaults() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &TableStruct::InitDefaultsImpl);
}
void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] = {
      "\nCtensorflow_serving/servables/tensorflo"
      "w/session_bundle_config.proto\022\022tensorflo"
      "w.serving\032\036google/protobuf/wrappers.prot"
      "o\032%tensorflow/core/protobuf/config.proto"
      "\032+tensorflow/core/protobuf/named_tensor."
      "proto\"\264\002\n\023SessionBundleConfig\022\026\n\016session"
      "_target\030\001 \001(\t\022/\n\016session_config\030\002 \001(\0132\027."
      "tensorflow.ConfigProto\022C\n\023batching_param"
      "eters\030\003 \001(\0132&.tensorflow.serving.Batchin"
      "gParameters\022F\n!session_run_load_threadpo"
      "ol_index\030\004 \001(\0132\033.google.protobuf.Int32Va"
      "lue\022G\n experimental_fixed_input_tensors\030"
      "\212\006 \003(\0132\034.tensorflow.NamedTensorProto\"\314\002\n"
      "\022BatchingParameters\0223\n\016max_batch_size\030\001 "
      "\001(\0132\033.google.protobuf.Int64Value\0229\n\024batc"
      "h_timeout_micros\030\002 \001(\0132\033.google.protobuf"
      ".Int64Value\0229\n\024max_enqueued_batches\030\003 \001("
      "\0132\033.google.protobuf.Int64Value\0226\n\021num_ba"
      "tch_threads\030\004 \001(\0132\033.google.protobuf.Int6"
      "4Value\0226\n\020thread_pool_name\030\005 \001(\0132\034.googl"
      "e.protobuf.StringValue\022\033\n\023allowed_batch_"
      "sizes\030\006 \003(\003b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 859);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/servables/tensorflow/session_bundle_config.proto", &protobuf_RegisterTypes);
  ::google::protobuf::protobuf_google_2fprotobuf_2fwrappers_2eproto::AddDescriptors();
  ::tensorflow::protobuf_tensorflow_2fcore_2fprotobuf_2fconfig_2eproto::AddDescriptors();
  ::tensorflow::protobuf_tensorflow_2fcore_2fprotobuf_2fnamed_5ftensor_2eproto::AddDescriptors();
  ::google::protobuf::internal::OnShutdown(&TableStruct::Shutdown);
}

void AddDescriptors() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;

}  // namespace protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto


// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int SessionBundleConfig::kSessionTargetFieldNumber;
const int SessionBundleConfig::kSessionConfigFieldNumber;
const int SessionBundleConfig::kBatchingParametersFieldNumber;
const int SessionBundleConfig::kSessionRunLoadThreadpoolIndexFieldNumber;
const int SessionBundleConfig::kExperimentalFixedInputTensorsFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

SessionBundleConfig::SessionBundleConfig()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.SessionBundleConfig)
}
SessionBundleConfig::SessionBundleConfig(const SessionBundleConfig& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      experimental_fixed_input_tensors_(from.experimental_fixed_input_tensors_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  session_target_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.session_target().size() > 0) {
    session_target_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_target_);
  }
  if (from.has_session_config()) {
    session_config_ = new ::tensorflow::ConfigProto(*from.session_config_);
  } else {
    session_config_ = NULL;
  }
  if (from.has_batching_parameters()) {
    batching_parameters_ = new ::tensorflow::serving::BatchingParameters(*from.batching_parameters_);
  } else {
    batching_parameters_ = NULL;
  }
  if (from.has_session_run_load_threadpool_index()) {
    session_run_load_threadpool_index_ = new ::google::protobuf::Int32Value(*from.session_run_load_threadpool_index_);
  } else {
    session_run_load_threadpool_index_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.SessionBundleConfig)
}

void SessionBundleConfig::SharedCtor() {
  session_target_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  ::memset(&session_config_, 0, reinterpret_cast<char*>(&session_run_load_threadpool_index_) -
    reinterpret_cast<char*>(&session_config_) + sizeof(session_run_load_threadpool_index_));
  _cached_size_ = 0;
}

SessionBundleConfig::~SessionBundleConfig() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.SessionBundleConfig)
  SharedDtor();
}

void SessionBundleConfig::SharedDtor() {
  session_target_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) {
    delete session_config_;
  }
  if (this != internal_default_instance()) {
    delete batching_parameters_;
  }
  if (this != internal_default_instance()) {
    delete session_run_load_threadpool_index_;
  }
}

void SessionBundleConfig::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* SessionBundleConfig::descriptor() {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[0].descriptor;
}

const SessionBundleConfig& SessionBundleConfig::default_instance() {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::InitDefaults();
  return *internal_default_instance();
}

SessionBundleConfig* SessionBundleConfig::New(::google::protobuf::Arena* arena) const {
  SessionBundleConfig* n = new SessionBundleConfig;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void SessionBundleConfig::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.SessionBundleConfig)
  experimental_fixed_input_tensors_.Clear();
  session_target_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (GetArenaNoVirtual() == NULL && session_config_ != NULL) {
    delete session_config_;
  }
  session_config_ = NULL;
  if (GetArenaNoVirtual() == NULL && batching_parameters_ != NULL) {
    delete batching_parameters_;
  }
  batching_parameters_ = NULL;
  if (GetArenaNoVirtual() == NULL && session_run_load_threadpool_index_ != NULL) {
    delete session_run_load_threadpool_index_;
  }
  session_run_load_threadpool_index_ = NULL;
}

bool SessionBundleConfig::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.SessionBundleConfig)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(16383u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // string session_target = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_session_target()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->session_target().data(), this->session_target().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.SessionBundleConfig.session_target"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.ConfigProto session_config = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_session_config()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .tensorflow.serving.BatchingParameters batching_parameters = 3;
      case 3: {
        if (tag == 26u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_batching_parameters()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
      case 4: {
        if (tag == 34u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_session_run_load_threadpool_index()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated .tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
      case 778: {
        if (tag == 6226u) {
          DO_(input->IncrementRecursionDepth());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_experimental_fixed_input_tensors()));
        } else {
          goto handle_unusual;
        }
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.SessionBundleConfig)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.SessionBundleConfig)
  return false;
#undef DO_
}

void SessionBundleConfig::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.SessionBundleConfig)
  // string session_target = 1;
  if (this->session_target().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_target().data(), this->session_target().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.session_target");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->session_target(), output);
  }

  // .tensorflow.ConfigProto session_config = 2;
  if (this->has_session_config()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->session_config_, output);
  }

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  if (this->has_batching_parameters()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, *this->batching_parameters_, output);
  }

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  if (this->has_session_run_load_threadpool_index()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, *this->session_run_load_threadpool_index_, output);
  }

  // repeated .tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  for (unsigned int i = 0, n = this->experimental_fixed_input_tensors_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      778, this->experimental_fixed_input_tensors(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.SessionBundleConfig)
}

::google::protobuf::uint8* SessionBundleConfig::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.SessionBundleConfig)
  // string session_target = 1;
  if (this->session_target().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->session_target().data(), this->session_target().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.SessionBundleConfig.session_target");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->session_target(), target);
  }

  // .tensorflow.ConfigProto session_config = 2;
  if (this->has_session_config()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *this->session_config_, false, target);
  }

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  if (this->has_batching_parameters()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        3, *this->batching_parameters_, false, target);
  }

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  if (this->has_session_run_load_threadpool_index()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        4, *this->session_run_load_threadpool_index_, false, target);
  }

  // repeated .tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  for (unsigned int i = 0, n = this->experimental_fixed_input_tensors_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        778, this->experimental_fixed_input_tensors(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.SessionBundleConfig)
  return target;
}

size_t SessionBundleConfig::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.SessionBundleConfig)
  size_t total_size = 0;

  // repeated .tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
  {
    unsigned int count = this->experimental_fixed_input_tensors_size();
    total_size += 2UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->experimental_fixed_input_tensors(i));
    }
  }

  // string session_target = 1;
  if (this->session_target().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->session_target());
  }

  // .tensorflow.ConfigProto session_config = 2;
  if (this->has_session_config()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->session_config_);
  }

  // .tensorflow.serving.BatchingParameters batching_parameters = 3;
  if (this->has_batching_parameters()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->batching_parameters_);
  }

  // .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
  if (this->has_session_run_load_threadpool_index()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->session_run_load_threadpool_index_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void SessionBundleConfig::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.SessionBundleConfig)
  GOOGLE_DCHECK_NE(&from, this);
  const SessionBundleConfig* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const SessionBundleConfig>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.SessionBundleConfig)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.SessionBundleConfig)
    MergeFrom(*source);
  }
}

void SessionBundleConfig::MergeFrom(const SessionBundleConfig& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.SessionBundleConfig)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  experimental_fixed_input_tensors_.MergeFrom(from.experimental_fixed_input_tensors_);
  if (from.session_target().size() > 0) {

    session_target_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.session_target_);
  }
  if (from.has_session_config()) {
    mutable_session_config()->::tensorflow::ConfigProto::MergeFrom(from.session_config());
  }
  if (from.has_batching_parameters()) {
    mutable_batching_parameters()->::tensorflow::serving::BatchingParameters::MergeFrom(from.batching_parameters());
  }
  if (from.has_session_run_load_threadpool_index()) {
    mutable_session_run_load_threadpool_index()->::google::protobuf::Int32Value::MergeFrom(from.session_run_load_threadpool_index());
  }
}

void SessionBundleConfig::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.SessionBundleConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void SessionBundleConfig::CopyFrom(const SessionBundleConfig& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.SessionBundleConfig)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool SessionBundleConfig::IsInitialized() const {
  return true;
}

void SessionBundleConfig::Swap(SessionBundleConfig* other) {
  if (other == this) return;
  InternalSwap(other);
}
void SessionBundleConfig::InternalSwap(SessionBundleConfig* other) {
  experimental_fixed_input_tensors_.UnsafeArenaSwap(&other->experimental_fixed_input_tensors_);
  session_target_.Swap(&other->session_target_);
  std::swap(session_config_, other->session_config_);
  std::swap(batching_parameters_, other->batching_parameters_);
  std::swap(session_run_load_threadpool_index_, other->session_run_load_threadpool_index_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata SessionBundleConfig::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[0];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// SessionBundleConfig

// string session_target = 1;
void SessionBundleConfig::clear_session_target() {
  session_target_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
const ::std::string& SessionBundleConfig::session_target() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.session_target)
  return session_target_.GetNoArena();
}
void SessionBundleConfig::set_session_target(const ::std::string& value) {
  
  session_target_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.SessionBundleConfig.session_target)
}
#if LANG_CXX11
void SessionBundleConfig::set_session_target(::std::string&& value) {
  
  session_target_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:tensorflow.serving.SessionBundleConfig.session_target)
}
#endif
void SessionBundleConfig::set_session_target(const char* value) {
  
  session_target_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.SessionBundleConfig.session_target)
}
void SessionBundleConfig::set_session_target(const char* value, size_t size) {
  
  session_target_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.SessionBundleConfig.session_target)
}
::std::string* SessionBundleConfig::mutable_session_target() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.session_target)
  return session_target_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
::std::string* SessionBundleConfig::release_session_target() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionBundleConfig.session_target)
  
  return session_target_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
void SessionBundleConfig::set_allocated_session_target(::std::string* session_target) {
  if (session_target != NULL) {
    
  } else {
    
  }
  session_target_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), session_target);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionBundleConfig.session_target)
}

// .tensorflow.ConfigProto session_config = 2;
bool SessionBundleConfig::has_session_config() const {
  return this != internal_default_instance() && session_config_ != NULL;
}
void SessionBundleConfig::clear_session_config() {
  if (GetArenaNoVirtual() == NULL && session_config_ != NULL) delete session_config_;
  session_config_ = NULL;
}
const ::tensorflow::ConfigProto& SessionBundleConfig::session_config() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.session_config)
  return session_config_ != NULL ? *session_config_
                         : *::tensorflow::ConfigProto::internal_default_instance();
}
::tensorflow::ConfigProto* SessionBundleConfig::mutable_session_config() {
  
  if (session_config_ == NULL) {
    session_config_ = new ::tensorflow::ConfigProto;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.session_config)
  return session_config_;
}
::tensorflow::ConfigProto* SessionBundleConfig::release_session_config() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionBundleConfig.session_config)
  
  ::tensorflow::ConfigProto* temp = session_config_;
  session_config_ = NULL;
  return temp;
}
void SessionBundleConfig::set_allocated_session_config(::tensorflow::ConfigProto* session_config) {
  delete session_config_;
  if (session_config != NULL && session_config->GetArena() != NULL) {
    ::tensorflow::ConfigProto* new_session_config = new ::tensorflow::ConfigProto;
    new_session_config->CopyFrom(*session_config);
    session_config = new_session_config;
  }
  session_config_ = session_config;
  if (session_config) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionBundleConfig.session_config)
}

// .tensorflow.serving.BatchingParameters batching_parameters = 3;
bool SessionBundleConfig::has_batching_parameters() const {
  return this != internal_default_instance() && batching_parameters_ != NULL;
}
void SessionBundleConfig::clear_batching_parameters() {
  if (GetArenaNoVirtual() == NULL && batching_parameters_ != NULL) delete batching_parameters_;
  batching_parameters_ = NULL;
}
const ::tensorflow::serving::BatchingParameters& SessionBundleConfig::batching_parameters() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.batching_parameters)
  return batching_parameters_ != NULL ? *batching_parameters_
                         : *::tensorflow::serving::BatchingParameters::internal_default_instance();
}
::tensorflow::serving::BatchingParameters* SessionBundleConfig::mutable_batching_parameters() {
  
  if (batching_parameters_ == NULL) {
    batching_parameters_ = new ::tensorflow::serving::BatchingParameters;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.batching_parameters)
  return batching_parameters_;
}
::tensorflow::serving::BatchingParameters* SessionBundleConfig::release_batching_parameters() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionBundleConfig.batching_parameters)
  
  ::tensorflow::serving::BatchingParameters* temp = batching_parameters_;
  batching_parameters_ = NULL;
  return temp;
}
void SessionBundleConfig::set_allocated_batching_parameters(::tensorflow::serving::BatchingParameters* batching_parameters) {
  delete batching_parameters_;
  batching_parameters_ = batching_parameters;
  if (batching_parameters) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionBundleConfig.batching_parameters)
}

// .google.protobuf.Int32Value session_run_load_threadpool_index = 4;
bool SessionBundleConfig::has_session_run_load_threadpool_index() const {
  return this != internal_default_instance() && session_run_load_threadpool_index_ != NULL;
}
void SessionBundleConfig::clear_session_run_load_threadpool_index() {
  if (GetArenaNoVirtual() == NULL && session_run_load_threadpool_index_ != NULL) delete session_run_load_threadpool_index_;
  session_run_load_threadpool_index_ = NULL;
}
const ::google::protobuf::Int32Value& SessionBundleConfig::session_run_load_threadpool_index() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.session_run_load_threadpool_index)
  return session_run_load_threadpool_index_ != NULL ? *session_run_load_threadpool_index_
                         : *::google::protobuf::Int32Value::internal_default_instance();
}
::google::protobuf::Int32Value* SessionBundleConfig::mutable_session_run_load_threadpool_index() {
  
  if (session_run_load_threadpool_index_ == NULL) {
    session_run_load_threadpool_index_ = new ::google::protobuf::Int32Value;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.session_run_load_threadpool_index)
  return session_run_load_threadpool_index_;
}
::google::protobuf::Int32Value* SessionBundleConfig::release_session_run_load_threadpool_index() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.SessionBundleConfig.session_run_load_threadpool_index)
  
  ::google::protobuf::Int32Value* temp = session_run_load_threadpool_index_;
  session_run_load_threadpool_index_ = NULL;
  return temp;
}
void SessionBundleConfig::set_allocated_session_run_load_threadpool_index(::google::protobuf::Int32Value* session_run_load_threadpool_index) {
  delete session_run_load_threadpool_index_;
  if (session_run_load_threadpool_index != NULL && session_run_load_threadpool_index->GetArena() != NULL) {
    ::google::protobuf::Int32Value* new_session_run_load_threadpool_index = new ::google::protobuf::Int32Value;
    new_session_run_load_threadpool_index->CopyFrom(*session_run_load_threadpool_index);
    session_run_load_threadpool_index = new_session_run_load_threadpool_index;
  }
  session_run_load_threadpool_index_ = session_run_load_threadpool_index;
  if (session_run_load_threadpool_index) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.SessionBundleConfig.session_run_load_threadpool_index)
}

// repeated .tensorflow.NamedTensorProto experimental_fixed_input_tensors = 778;
int SessionBundleConfig::experimental_fixed_input_tensors_size() const {
  return experimental_fixed_input_tensors_.size();
}
void SessionBundleConfig::clear_experimental_fixed_input_tensors() {
  experimental_fixed_input_tensors_.Clear();
}
const ::tensorflow::NamedTensorProto& SessionBundleConfig::experimental_fixed_input_tensors(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return experimental_fixed_input_tensors_.Get(index);
}
::tensorflow::NamedTensorProto* SessionBundleConfig::mutable_experimental_fixed_input_tensors(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return experimental_fixed_input_tensors_.Mutable(index);
}
::tensorflow::NamedTensorProto* SessionBundleConfig::add_experimental_fixed_input_tensors() {
  // @@protoc_insertion_point(field_add:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return experimental_fixed_input_tensors_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >*
SessionBundleConfig::mutable_experimental_fixed_input_tensors() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return &experimental_fixed_input_tensors_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::NamedTensorProto >&
SessionBundleConfig::experimental_fixed_input_tensors() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.SessionBundleConfig.experimental_fixed_input_tensors)
  return experimental_fixed_input_tensors_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int BatchingParameters::kMaxBatchSizeFieldNumber;
const int BatchingParameters::kBatchTimeoutMicrosFieldNumber;
const int BatchingParameters::kMaxEnqueuedBatchesFieldNumber;
const int BatchingParameters::kNumBatchThreadsFieldNumber;
const int BatchingParameters::kThreadPoolNameFieldNumber;
const int BatchingParameters::kAllowedBatchSizesFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

BatchingParameters::BatchingParameters()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.BatchingParameters)
}
BatchingParameters::BatchingParameters(const BatchingParameters& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      allowed_batch_sizes_(from.allowed_batch_sizes_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_max_batch_size()) {
    max_batch_size_ = new ::google::protobuf::Int64Value(*from.max_batch_size_);
  } else {
    max_batch_size_ = NULL;
  }
  if (from.has_batch_timeout_micros()) {
    batch_timeout_micros_ = new ::google::protobuf::Int64Value(*from.batch_timeout_micros_);
  } else {
    batch_timeout_micros_ = NULL;
  }
  if (from.has_max_enqueued_batches()) {
    max_enqueued_batches_ = new ::google::protobuf::Int64Value(*from.max_enqueued_batches_);
  } else {
    max_enqueued_batches_ = NULL;
  }
  if (from.has_num_batch_threads()) {
    num_batch_threads_ = new ::google::protobuf::Int64Value(*from.num_batch_threads_);
  } else {
    num_batch_threads_ = NULL;
  }
  if (from.has_thread_pool_name()) {
    thread_pool_name_ = new ::google::protobuf::StringValue(*from.thread_pool_name_);
  } else {
    thread_pool_name_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.BatchingParameters)
}

void BatchingParameters::SharedCtor() {
  ::memset(&max_batch_size_, 0, reinterpret_cast<char*>(&thread_pool_name_) -
    reinterpret_cast<char*>(&max_batch_size_) + sizeof(thread_pool_name_));
  _cached_size_ = 0;
}

BatchingParameters::~BatchingParameters() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.BatchingParameters)
  SharedDtor();
}

void BatchingParameters::SharedDtor() {
  if (this != internal_default_instance()) {
    delete max_batch_size_;
  }
  if (this != internal_default_instance()) {
    delete batch_timeout_micros_;
  }
  if (this != internal_default_instance()) {
    delete max_enqueued_batches_;
  }
  if (this != internal_default_instance()) {
    delete num_batch_threads_;
  }
  if (this != internal_default_instance()) {
    delete thread_pool_name_;
  }
}

void BatchingParameters::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* BatchingParameters::descriptor() {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[1].descriptor;
}

const BatchingParameters& BatchingParameters::default_instance() {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::InitDefaults();
  return *internal_default_instance();
}

BatchingParameters* BatchingParameters::New(::google::protobuf::Arena* arena) const {
  BatchingParameters* n = new BatchingParameters;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void BatchingParameters::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.BatchingParameters)
  allowed_batch_sizes_.Clear();
  if (GetArenaNoVirtual() == NULL && max_batch_size_ != NULL) {
    delete max_batch_size_;
  }
  max_batch_size_ = NULL;
  if (GetArenaNoVirtual() == NULL && batch_timeout_micros_ != NULL) {
    delete batch_timeout_micros_;
  }
  batch_timeout_micros_ = NULL;
  if (GetArenaNoVirtual() == NULL && max_enqueued_batches_ != NULL) {
    delete max_enqueued_batches_;
  }
  max_enqueued_batches_ = NULL;
  if (GetArenaNoVirtual() == NULL && num_batch_threads_ != NULL) {
    delete num_batch_threads_;
  }
  num_batch_threads_ = NULL;
  if (GetArenaNoVirtual() == NULL && thread_pool_name_ != NULL) {
    delete thread_pool_name_;
  }
  thread_pool_name_ = NULL;
}

bool BatchingParameters::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.BatchingParameters)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .google.protobuf.Int64Value max_batch_size = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_max_batch_size()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value batch_timeout_micros = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_batch_timeout_micros()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value max_enqueued_batches = 3;
      case 3: {
        if (tag == 26u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_max_enqueued_batches()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.Int64Value num_batch_threads = 4;
      case 4: {
        if (tag == 34u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_num_batch_threads()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.StringValue thread_pool_name = 5;
      case 5: {
        if (tag == 42u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_thread_pool_name()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // repeated int64 allowed_batch_sizes = 6;
      case 6: {
        if (tag == 50u) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadPackedPrimitive<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 input, this->mutable_allowed_batch_sizes())));
        } else if (tag == 48u) {
          DO_((::google::protobuf::internal::WireFormatLite::ReadRepeatedPrimitiveNoInline<
                   ::google::protobuf::int64, ::google::protobuf::internal::WireFormatLite::TYPE_INT64>(
                 1, 50u, input, this->mutable_allowed_batch_sizes())));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.BatchingParameters)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.BatchingParameters)
  return false;
#undef DO_
}

void BatchingParameters::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.BatchingParameters)
  // .google.protobuf.Int64Value max_batch_size = 1;
  if (this->has_max_batch_size()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->max_batch_size_, output);
  }

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  if (this->has_batch_timeout_micros()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->batch_timeout_micros_, output);
  }

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  if (this->has_max_enqueued_batches()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      3, *this->max_enqueued_batches_, output);
  }

  // .google.protobuf.Int64Value num_batch_threads = 4;
  if (this->has_num_batch_threads()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      4, *this->num_batch_threads_, output);
  }

  // .google.protobuf.StringValue thread_pool_name = 5;
  if (this->has_thread_pool_name()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      5, *this->thread_pool_name_, output);
  }

  // repeated int64 allowed_batch_sizes = 6;
  if (this->allowed_batch_sizes_size() > 0) {
    ::google::protobuf::internal::WireFormatLite::WriteTag(6, ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED, output);
    output->WriteVarint32(_allowed_batch_sizes_cached_byte_size_);
  }
  for (int i = 0; i < this->allowed_batch_sizes_size(); i++) {
    ::google::protobuf::internal::WireFormatLite::WriteInt64NoTag(
      this->allowed_batch_sizes(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.BatchingParameters)
}

::google::protobuf::uint8* BatchingParameters::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.BatchingParameters)
  // .google.protobuf.Int64Value max_batch_size = 1;
  if (this->has_max_batch_size()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->max_batch_size_, false, target);
  }

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  if (this->has_batch_timeout_micros()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *this->batch_timeout_micros_, false, target);
  }

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  if (this->has_max_enqueued_batches()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        3, *this->max_enqueued_batches_, false, target);
  }

  // .google.protobuf.Int64Value num_batch_threads = 4;
  if (this->has_num_batch_threads()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        4, *this->num_batch_threads_, false, target);
  }

  // .google.protobuf.StringValue thread_pool_name = 5;
  if (this->has_thread_pool_name()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        5, *this->thread_pool_name_, false, target);
  }

  // repeated int64 allowed_batch_sizes = 6;
  if (this->allowed_batch_sizes_size() > 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteTagToArray(
      6,
      ::google::protobuf::internal::WireFormatLite::WIRETYPE_LENGTH_DELIMITED,
      target);
    target = ::google::protobuf::io::CodedOutputStream::WriteVarint32ToArray(
      _allowed_batch_sizes_cached_byte_size_, target);
  }
  for (int i = 0; i < this->allowed_batch_sizes_size(); i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      WriteInt64NoTagToArray(this->allowed_batch_sizes(i), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.BatchingParameters)
  return target;
}

size_t BatchingParameters::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.BatchingParameters)
  size_t total_size = 0;

  // repeated int64 allowed_batch_sizes = 6;
  {
    size_t data_size = ::google::protobuf::internal::WireFormatLite::
      Int64Size(this->allowed_batch_sizes_);
    if (data_size > 0) {
      total_size += 1 +
        ::google::protobuf::internal::WireFormatLite::Int32Size(data_size);
    }
    int cached_size = ::google::protobuf::internal::ToCachedSize(data_size);
    GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
    _allowed_batch_sizes_cached_byte_size_ = cached_size;
    GOOGLE_SAFE_CONCURRENT_WRITES_END();
    total_size += data_size;
  }

  // .google.protobuf.Int64Value max_batch_size = 1;
  if (this->has_max_batch_size()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->max_batch_size_);
  }

  // .google.protobuf.Int64Value batch_timeout_micros = 2;
  if (this->has_batch_timeout_micros()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->batch_timeout_micros_);
  }

  // .google.protobuf.Int64Value max_enqueued_batches = 3;
  if (this->has_max_enqueued_batches()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->max_enqueued_batches_);
  }

  // .google.protobuf.Int64Value num_batch_threads = 4;
  if (this->has_num_batch_threads()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->num_batch_threads_);
  }

  // .google.protobuf.StringValue thread_pool_name = 5;
  if (this->has_thread_pool_name()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->thread_pool_name_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void BatchingParameters::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.BatchingParameters)
  GOOGLE_DCHECK_NE(&from, this);
  const BatchingParameters* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const BatchingParameters>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.BatchingParameters)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.BatchingParameters)
    MergeFrom(*source);
  }
}

void BatchingParameters::MergeFrom(const BatchingParameters& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.BatchingParameters)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  allowed_batch_sizes_.MergeFrom(from.allowed_batch_sizes_);
  if (from.has_max_batch_size()) {
    mutable_max_batch_size()->::google::protobuf::Int64Value::MergeFrom(from.max_batch_size());
  }
  if (from.has_batch_timeout_micros()) {
    mutable_batch_timeout_micros()->::google::protobuf::Int64Value::MergeFrom(from.batch_timeout_micros());
  }
  if (from.has_max_enqueued_batches()) {
    mutable_max_enqueued_batches()->::google::protobuf::Int64Value::MergeFrom(from.max_enqueued_batches());
  }
  if (from.has_num_batch_threads()) {
    mutable_num_batch_threads()->::google::protobuf::Int64Value::MergeFrom(from.num_batch_threads());
  }
  if (from.has_thread_pool_name()) {
    mutable_thread_pool_name()->::google::protobuf::StringValue::MergeFrom(from.thread_pool_name());
  }
}

void BatchingParameters::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.BatchingParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void BatchingParameters::CopyFrom(const BatchingParameters& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.BatchingParameters)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool BatchingParameters::IsInitialized() const {
  return true;
}

void BatchingParameters::Swap(BatchingParameters* other) {
  if (other == this) return;
  InternalSwap(other);
}
void BatchingParameters::InternalSwap(BatchingParameters* other) {
  allowed_batch_sizes_.UnsafeArenaSwap(&other->allowed_batch_sizes_);
  std::swap(max_batch_size_, other->max_batch_size_);
  std::swap(batch_timeout_micros_, other->batch_timeout_micros_);
  std::swap(max_enqueued_batches_, other->max_enqueued_batches_);
  std::swap(num_batch_threads_, other->num_batch_threads_);
  std::swap(thread_pool_name_, other->thread_pool_name_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata BatchingParameters::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fservables_2ftensorflow_2fsession_5fbundle_5fconfig_2eproto::file_level_metadata[1];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// BatchingParameters

// .google.protobuf.Int64Value max_batch_size = 1;
bool BatchingParameters::has_max_batch_size() const {
  return this != internal_default_instance() && max_batch_size_ != NULL;
}
void BatchingParameters::clear_max_batch_size() {
  if (GetArenaNoVirtual() == NULL && max_batch_size_ != NULL) delete max_batch_size_;
  max_batch_size_ = NULL;
}
const ::google::protobuf::Int64Value& BatchingParameters::max_batch_size() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.max_batch_size)
  return max_batch_size_ != NULL ? *max_batch_size_
                         : *::google::protobuf::Int64Value::internal_default_instance();
}
::google::protobuf::Int64Value* BatchingParameters::mutable_max_batch_size() {
  
  if (max_batch_size_ == NULL) {
    max_batch_size_ = new ::google::protobuf::Int64Value;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.max_batch_size)
  return max_batch_size_;
}
::google::protobuf::Int64Value* BatchingParameters::release_max_batch_size() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.max_batch_size)
  
  ::google::protobuf::Int64Value* temp = max_batch_size_;
  max_batch_size_ = NULL;
  return temp;
}
void BatchingParameters::set_allocated_max_batch_size(::google::protobuf::Int64Value* max_batch_size) {
  delete max_batch_size_;
  if (max_batch_size != NULL && max_batch_size->GetArena() != NULL) {
    ::google::protobuf::Int64Value* new_max_batch_size = new ::google::protobuf::Int64Value;
    new_max_batch_size->CopyFrom(*max_batch_size);
    max_batch_size = new_max_batch_size;
  }
  max_batch_size_ = max_batch_size;
  if (max_batch_size) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.max_batch_size)
}

// .google.protobuf.Int64Value batch_timeout_micros = 2;
bool BatchingParameters::has_batch_timeout_micros() const {
  return this != internal_default_instance() && batch_timeout_micros_ != NULL;
}
void BatchingParameters::clear_batch_timeout_micros() {
  if (GetArenaNoVirtual() == NULL && batch_timeout_micros_ != NULL) delete batch_timeout_micros_;
  batch_timeout_micros_ = NULL;
}
const ::google::protobuf::Int64Value& BatchingParameters::batch_timeout_micros() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.batch_timeout_micros)
  return batch_timeout_micros_ != NULL ? *batch_timeout_micros_
                         : *::google::protobuf::Int64Value::internal_default_instance();
}
::google::protobuf::Int64Value* BatchingParameters::mutable_batch_timeout_micros() {
  
  if (batch_timeout_micros_ == NULL) {
    batch_timeout_micros_ = new ::google::protobuf::Int64Value;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.batch_timeout_micros)
  return batch_timeout_micros_;
}
::google::protobuf::Int64Value* BatchingParameters::release_batch_timeout_micros() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.batch_timeout_micros)
  
  ::google::protobuf::Int64Value* temp = batch_timeout_micros_;
  batch_timeout_micros_ = NULL;
  return temp;
}
void BatchingParameters::set_allocated_batch_timeout_micros(::google::protobuf::Int64Value* batch_timeout_micros) {
  delete batch_timeout_micros_;
  if (batch_timeout_micros != NULL && batch_timeout_micros->GetArena() != NULL) {
    ::google::protobuf::Int64Value* new_batch_timeout_micros = new ::google::protobuf::Int64Value;
    new_batch_timeout_micros->CopyFrom(*batch_timeout_micros);
    batch_timeout_micros = new_batch_timeout_micros;
  }
  batch_timeout_micros_ = batch_timeout_micros;
  if (batch_timeout_micros) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.batch_timeout_micros)
}

// .google.protobuf.Int64Value max_enqueued_batches = 3;
bool BatchingParameters::has_max_enqueued_batches() const {
  return this != internal_default_instance() && max_enqueued_batches_ != NULL;
}
void BatchingParameters::clear_max_enqueued_batches() {
  if (GetArenaNoVirtual() == NULL && max_enqueued_batches_ != NULL) delete max_enqueued_batches_;
  max_enqueued_batches_ = NULL;
}
const ::google::protobuf::Int64Value& BatchingParameters::max_enqueued_batches() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.max_enqueued_batches)
  return max_enqueued_batches_ != NULL ? *max_enqueued_batches_
                         : *::google::protobuf::Int64Value::internal_default_instance();
}
::google::protobuf::Int64Value* BatchingParameters::mutable_max_enqueued_batches() {
  
  if (max_enqueued_batches_ == NULL) {
    max_enqueued_batches_ = new ::google::protobuf::Int64Value;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.max_enqueued_batches)
  return max_enqueued_batches_;
}
::google::protobuf::Int64Value* BatchingParameters::release_max_enqueued_batches() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.max_enqueued_batches)
  
  ::google::protobuf::Int64Value* temp = max_enqueued_batches_;
  max_enqueued_batches_ = NULL;
  return temp;
}
void BatchingParameters::set_allocated_max_enqueued_batches(::google::protobuf::Int64Value* max_enqueued_batches) {
  delete max_enqueued_batches_;
  if (max_enqueued_batches != NULL && max_enqueued_batches->GetArena() != NULL) {
    ::google::protobuf::Int64Value* new_max_enqueued_batches = new ::google::protobuf::Int64Value;
    new_max_enqueued_batches->CopyFrom(*max_enqueued_batches);
    max_enqueued_batches = new_max_enqueued_batches;
  }
  max_enqueued_batches_ = max_enqueued_batches;
  if (max_enqueued_batches) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.max_enqueued_batches)
}

// .google.protobuf.Int64Value num_batch_threads = 4;
bool BatchingParameters::has_num_batch_threads() const {
  return this != internal_default_instance() && num_batch_threads_ != NULL;
}
void BatchingParameters::clear_num_batch_threads() {
  if (GetArenaNoVirtual() == NULL && num_batch_threads_ != NULL) delete num_batch_threads_;
  num_batch_threads_ = NULL;
}
const ::google::protobuf::Int64Value& BatchingParameters::num_batch_threads() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.num_batch_threads)
  return num_batch_threads_ != NULL ? *num_batch_threads_
                         : *::google::protobuf::Int64Value::internal_default_instance();
}
::google::protobuf::Int64Value* BatchingParameters::mutable_num_batch_threads() {
  
  if (num_batch_threads_ == NULL) {
    num_batch_threads_ = new ::google::protobuf::Int64Value;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.num_batch_threads)
  return num_batch_threads_;
}
::google::protobuf::Int64Value* BatchingParameters::release_num_batch_threads() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.num_batch_threads)
  
  ::google::protobuf::Int64Value* temp = num_batch_threads_;
  num_batch_threads_ = NULL;
  return temp;
}
void BatchingParameters::set_allocated_num_batch_threads(::google::protobuf::Int64Value* num_batch_threads) {
  delete num_batch_threads_;
  if (num_batch_threads != NULL && num_batch_threads->GetArena() != NULL) {
    ::google::protobuf::Int64Value* new_num_batch_threads = new ::google::protobuf::Int64Value;
    new_num_batch_threads->CopyFrom(*num_batch_threads);
    num_batch_threads = new_num_batch_threads;
  }
  num_batch_threads_ = num_batch_threads;
  if (num_batch_threads) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.num_batch_threads)
}

// .google.protobuf.StringValue thread_pool_name = 5;
bool BatchingParameters::has_thread_pool_name() const {
  return this != internal_default_instance() && thread_pool_name_ != NULL;
}
void BatchingParameters::clear_thread_pool_name() {
  if (GetArenaNoVirtual() == NULL && thread_pool_name_ != NULL) delete thread_pool_name_;
  thread_pool_name_ = NULL;
}
const ::google::protobuf::StringValue& BatchingParameters::thread_pool_name() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.thread_pool_name)
  return thread_pool_name_ != NULL ? *thread_pool_name_
                         : *::google::protobuf::StringValue::internal_default_instance();
}
::google::protobuf::StringValue* BatchingParameters::mutable_thread_pool_name() {
  
  if (thread_pool_name_ == NULL) {
    thread_pool_name_ = new ::google::protobuf::StringValue;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.BatchingParameters.thread_pool_name)
  return thread_pool_name_;
}
::google::protobuf::StringValue* BatchingParameters::release_thread_pool_name() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.BatchingParameters.thread_pool_name)
  
  ::google::protobuf::StringValue* temp = thread_pool_name_;
  thread_pool_name_ = NULL;
  return temp;
}
void BatchingParameters::set_allocated_thread_pool_name(::google::protobuf::StringValue* thread_pool_name) {
  delete thread_pool_name_;
  if (thread_pool_name != NULL && thread_pool_name->GetArena() != NULL) {
    ::google::protobuf::StringValue* new_thread_pool_name = new ::google::protobuf::StringValue;
    new_thread_pool_name->CopyFrom(*thread_pool_name);
    thread_pool_name = new_thread_pool_name;
  }
  thread_pool_name_ = thread_pool_name;
  if (thread_pool_name) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.BatchingParameters.thread_pool_name)
}

// repeated int64 allowed_batch_sizes = 6;
int BatchingParameters::allowed_batch_sizes_size() const {
  return allowed_batch_sizes_.size();
}
void BatchingParameters::clear_allowed_batch_sizes() {
  allowed_batch_sizes_.Clear();
}
::google::protobuf::int64 BatchingParameters::allowed_batch_sizes(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
  return allowed_batch_sizes_.Get(index);
}
void BatchingParameters::set_allowed_batch_sizes(int index, ::google::protobuf::int64 value) {
  allowed_batch_sizes_.Set(index, value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
}
void BatchingParameters::add_allowed_batch_sizes(::google::protobuf::int64 value) {
  allowed_batch_sizes_.Add(value);
  // @@protoc_insertion_point(field_add:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
}
const ::google::protobuf::RepeatedField< ::google::protobuf::int64 >&
BatchingParameters::allowed_batch_sizes() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
  return allowed_batch_sizes_;
}
::google::protobuf::RepeatedField< ::google::protobuf::int64 >*
BatchingParameters::mutable_allowed_batch_sizes() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.BatchingParameters.allowed_batch_sizes)
  return &allowed_batch_sizes_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
