// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: tensorflow_serving/resources/resources.proto

#define INTERNAL_SUPPRESS_PROTOBUF_FIELD_DEPRECATION
#include "tensorflow_serving/resources/resources.pb.h"

#include <algorithm>

#include <google/protobuf/stubs/common.h>
#include <google/protobuf/stubs/port.h>
#include <google/protobuf/stubs/once.h>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/wire_format_lite_inl.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)

namespace tensorflow {
namespace serving {
class ResourceDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<Resource> {
} _Resource_default_instance_;
class ResourceAllocation_EntryDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<ResourceAllocation_Entry> {
} _ResourceAllocation_Entry_default_instance_;
class ResourceAllocationDefaultTypeInternal : public ::google::protobuf::internal::ExplicitlyConstructed<ResourceAllocation> {
} _ResourceAllocation_default_instance_;

namespace protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto {


namespace {

::google::protobuf::Metadata file_level_metadata[3];

}  // namespace

const ::google::protobuf::uint32 TableStruct::offsets[] = {
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Resource, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Resource, device_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Resource, device_instance_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(Resource, kind_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResourceAllocation_Entry, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResourceAllocation_Entry, resource_),
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResourceAllocation_Entry, quantity_),
  ~0u,  // no _has_bits_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResourceAllocation, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  GOOGLE_PROTOBUF_GENERATED_MESSAGE_FIELD_OFFSET(ResourceAllocation, resource_quantities_),
};

static const ::google::protobuf::internal::MigrationSchema schemas[] = {
  { 0, -1, sizeof(Resource)},
  { 7, -1, sizeof(ResourceAllocation_Entry)},
  { 13, -1, sizeof(ResourceAllocation)},
};

static ::google::protobuf::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::google::protobuf::Message*>(&_Resource_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&_ResourceAllocation_Entry_default_instance_),
  reinterpret_cast<const ::google::protobuf::Message*>(&_ResourceAllocation_default_instance_),
};

namespace {

void protobuf_AssignDescriptors() {
  AddDescriptors();
  ::google::protobuf::MessageFactory* factory = NULL;
  AssignDescriptors(
      "tensorflow_serving/resources/resources.proto", schemas, file_default_instances, TableStruct::offsets, factory,
      file_level_metadata, NULL, NULL);
}

void protobuf_AssignDescriptorsOnce() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &protobuf_AssignDescriptors);
}

void protobuf_RegisterTypes(const ::std::string&) GOOGLE_ATTRIBUTE_COLD;
void protobuf_RegisterTypes(const ::std::string&) {
  protobuf_AssignDescriptorsOnce();
  ::google::protobuf::internal::RegisterAllTypes(file_level_metadata, 3);
}

}  // namespace

void TableStruct::Shutdown() {
  _Resource_default_instance_.Shutdown();
  delete file_level_metadata[0].reflection;
  _ResourceAllocation_Entry_default_instance_.Shutdown();
  delete file_level_metadata[1].reflection;
  _ResourceAllocation_default_instance_.Shutdown();
  delete file_level_metadata[2].reflection;
}

void TableStruct::InitDefaultsImpl() {
  GOOGLE_PROTOBUF_VERIFY_VERSION;

  ::google::protobuf::internal::InitProtobufDefaults();
  ::google::protobuf::protobuf_google_2fprotobuf_2fwrappers_2eproto::InitDefaults();
  _Resource_default_instance_.DefaultConstruct();
  _ResourceAllocation_Entry_default_instance_.DefaultConstruct();
  _ResourceAllocation_default_instance_.DefaultConstruct();
  _Resource_default_instance_.get_mutable()->device_instance_ = const_cast< ::google::protobuf::UInt32Value*>(
      ::google::protobuf::UInt32Value::internal_default_instance());
  _ResourceAllocation_Entry_default_instance_.get_mutable()->resource_ = const_cast< ::tensorflow::serving::Resource*>(
      ::tensorflow::serving::Resource::internal_default_instance());
}

void InitDefaults() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &TableStruct::InitDefaultsImpl);
}
void AddDescriptorsImpl() {
  InitDefaults();
  static const char descriptor[] = {
      "\n,tensorflow_serving/resources/resources"
      ".proto\022\022tensorflow.serving\032\036google/proto"
      "buf/wrappers.proto\"_\n\010Resource\022\016\n\006device"
      "\030\001 \001(\t\0225\n\017device_instance\030\002 \001(\0132\034.google"
      ".protobuf.UInt32Value\022\014\n\004kind\030\003 \001(\t\"\252\001\n\022"
      "ResourceAllocation\022I\n\023resource_quantitie"
      "s\030\001 \003(\0132,.tensorflow.serving.ResourceAll"
      "ocation.Entry\032I\n\005Entry\022.\n\010resource\030\001 \001(\013"
      "2\034.tensorflow.serving.Resource\022\020\n\010quanti"
      "ty\030\002 \001(\004b\006proto3"
  };
  ::google::protobuf::DescriptorPool::InternalAddGeneratedFile(
      descriptor, 376);
  ::google::protobuf::MessageFactory::InternalRegisterGeneratedFile(
    "tensorflow_serving/resources/resources.proto", &protobuf_RegisterTypes);
  ::google::protobuf::protobuf_google_2fprotobuf_2fwrappers_2eproto::AddDescriptors();
  ::google::protobuf::internal::OnShutdown(&TableStruct::Shutdown);
}

void AddDescriptors() {
  static GOOGLE_PROTOBUF_DECLARE_ONCE(once);
  ::google::protobuf::GoogleOnceInit(&once, &AddDescriptorsImpl);
}
// Force AddDescriptors() to be called at static initialization time.
struct StaticDescriptorInitializer {
  StaticDescriptorInitializer() {
    AddDescriptors();
  }
} static_descriptor_initializer;

}  // namespace protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto


// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int Resource::kDeviceFieldNumber;
const int Resource::kDeviceInstanceFieldNumber;
const int Resource::kKindFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

Resource::Resource()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.Resource)
}
Resource::Resource(const Resource& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  device_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.device().size() > 0) {
    device_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.device_);
  }
  kind_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (from.kind().size() > 0) {
    kind_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.kind_);
  }
  if (from.has_device_instance()) {
    device_instance_ = new ::google::protobuf::UInt32Value(*from.device_instance_);
  } else {
    device_instance_ = NULL;
  }
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.Resource)
}

void Resource::SharedCtor() {
  device_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  kind_.UnsafeSetDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  device_instance_ = NULL;
  _cached_size_ = 0;
}

Resource::~Resource() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.Resource)
  SharedDtor();
}

void Resource::SharedDtor() {
  device_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  kind_.DestroyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) {
    delete device_instance_;
  }
}

void Resource::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* Resource::descriptor() {
  protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::file_level_metadata[0].descriptor;
}

const Resource& Resource::default_instance() {
  protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::InitDefaults();
  return *internal_default_instance();
}

Resource* Resource::New(::google::protobuf::Arena* arena) const {
  Resource* n = new Resource;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void Resource::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.Resource)
  device_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  kind_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
  if (GetArenaNoVirtual() == NULL && device_instance_ != NULL) {
    delete device_instance_;
  }
  device_instance_ = NULL;
}

bool Resource::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.Resource)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // string device = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_device()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->device().data(), this->device().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.Resource.device"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // .google.protobuf.UInt32Value device_instance = 2;
      case 2: {
        if (tag == 18u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_device_instance()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // string kind = 3;
      case 3: {
        if (tag == 26u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadString(
                input, this->mutable_kind()));
          DO_(::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
            this->kind().data(), this->kind().length(),
            ::google::protobuf::internal::WireFormatLite::PARSE,
            "tensorflow.serving.Resource.kind"));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.Resource)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.Resource)
  return false;
#undef DO_
}

void Resource::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.Resource)
  // string device = 1;
  if (this->device().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device().data(), this->device().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.Resource.device");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      1, this->device(), output);
  }

  // .google.protobuf.UInt32Value device_instance = 2;
  if (this->has_device_instance()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      2, *this->device_instance_, output);
  }

  // string kind = 3;
  if (this->kind().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->kind().data(), this->kind().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.Resource.kind");
    ::google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(
      3, this->kind(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.Resource)
}

::google::protobuf::uint8* Resource::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.Resource)
  // string device = 1;
  if (this->device().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->device().data(), this->device().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.Resource.device");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        1, this->device(), target);
  }

  // .google.protobuf.UInt32Value device_instance = 2;
  if (this->has_device_instance()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        2, *this->device_instance_, false, target);
  }

  // string kind = 3;
  if (this->kind().size() > 0) {
    ::google::protobuf::internal::WireFormatLite::VerifyUtf8String(
      this->kind().data(), this->kind().length(),
      ::google::protobuf::internal::WireFormatLite::SERIALIZE,
      "tensorflow.serving.Resource.kind");
    target =
      ::google::protobuf::internal::WireFormatLite::WriteStringToArray(
        3, this->kind(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.Resource)
  return target;
}

size_t Resource::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.Resource)
  size_t total_size = 0;

  // string device = 1;
  if (this->device().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->device());
  }

  // string kind = 3;
  if (this->kind().size() > 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::StringSize(
        this->kind());
  }

  // .google.protobuf.UInt32Value device_instance = 2;
  if (this->has_device_instance()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->device_instance_);
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void Resource::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.Resource)
  GOOGLE_DCHECK_NE(&from, this);
  const Resource* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const Resource>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.Resource)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.Resource)
    MergeFrom(*source);
  }
}

void Resource::MergeFrom(const Resource& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.Resource)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.device().size() > 0) {

    device_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.device_);
  }
  if (from.kind().size() > 0) {

    kind_.AssignWithDefault(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), from.kind_);
  }
  if (from.has_device_instance()) {
    mutable_device_instance()->::google::protobuf::UInt32Value::MergeFrom(from.device_instance());
  }
}

void Resource::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.Resource)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void Resource::CopyFrom(const Resource& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.Resource)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool Resource::IsInitialized() const {
  return true;
}

void Resource::Swap(Resource* other) {
  if (other == this) return;
  InternalSwap(other);
}
void Resource::InternalSwap(Resource* other) {
  device_.Swap(&other->device_);
  kind_.Swap(&other->kind_);
  std::swap(device_instance_, other->device_instance_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata Resource::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::file_level_metadata[0];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// Resource

// string device = 1;
void Resource::clear_device() {
  device_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
const ::std::string& Resource::device() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.Resource.device)
  return device_.GetNoArena();
}
void Resource::set_device(const ::std::string& value) {
  
  device_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.Resource.device)
}
#if LANG_CXX11
void Resource::set_device(::std::string&& value) {
  
  device_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:tensorflow.serving.Resource.device)
}
#endif
void Resource::set_device(const char* value) {
  
  device_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.Resource.device)
}
void Resource::set_device(const char* value, size_t size) {
  
  device_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.Resource.device)
}
::std::string* Resource::mutable_device() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.Resource.device)
  return device_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
::std::string* Resource::release_device() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.Resource.device)
  
  return device_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
void Resource::set_allocated_device(::std::string* device) {
  if (device != NULL) {
    
  } else {
    
  }
  device_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), device);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.Resource.device)
}

// .google.protobuf.UInt32Value device_instance = 2;
bool Resource::has_device_instance() const {
  return this != internal_default_instance() && device_instance_ != NULL;
}
void Resource::clear_device_instance() {
  if (GetArenaNoVirtual() == NULL && device_instance_ != NULL) delete device_instance_;
  device_instance_ = NULL;
}
const ::google::protobuf::UInt32Value& Resource::device_instance() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.Resource.device_instance)
  return device_instance_ != NULL ? *device_instance_
                         : *::google::protobuf::UInt32Value::internal_default_instance();
}
::google::protobuf::UInt32Value* Resource::mutable_device_instance() {
  
  if (device_instance_ == NULL) {
    device_instance_ = new ::google::protobuf::UInt32Value;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.Resource.device_instance)
  return device_instance_;
}
::google::protobuf::UInt32Value* Resource::release_device_instance() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.Resource.device_instance)
  
  ::google::protobuf::UInt32Value* temp = device_instance_;
  device_instance_ = NULL;
  return temp;
}
void Resource::set_allocated_device_instance(::google::protobuf::UInt32Value* device_instance) {
  delete device_instance_;
  if (device_instance != NULL && device_instance->GetArena() != NULL) {
    ::google::protobuf::UInt32Value* new_device_instance = new ::google::protobuf::UInt32Value;
    new_device_instance->CopyFrom(*device_instance);
    device_instance = new_device_instance;
  }
  device_instance_ = device_instance;
  if (device_instance) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.Resource.device_instance)
}

// string kind = 3;
void Resource::clear_kind() {
  kind_.ClearToEmptyNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
const ::std::string& Resource::kind() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.Resource.kind)
  return kind_.GetNoArena();
}
void Resource::set_kind(const ::std::string& value) {
  
  kind_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), value);
  // @@protoc_insertion_point(field_set:tensorflow.serving.Resource.kind)
}
#if LANG_CXX11
void Resource::set_kind(::std::string&& value) {
  
  kind_.SetNoArena(
    &::google::protobuf::internal::GetEmptyStringAlreadyInited(), std::move(value));
  // @@protoc_insertion_point(field_set_rvalue:tensorflow.serving.Resource.kind)
}
#endif
void Resource::set_kind(const char* value) {
  
  kind_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), ::std::string(value));
  // @@protoc_insertion_point(field_set_char:tensorflow.serving.Resource.kind)
}
void Resource::set_kind(const char* value, size_t size) {
  
  kind_.SetNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(),
      ::std::string(reinterpret_cast<const char*>(value), size));
  // @@protoc_insertion_point(field_set_pointer:tensorflow.serving.Resource.kind)
}
::std::string* Resource::mutable_kind() {
  
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.Resource.kind)
  return kind_.MutableNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
::std::string* Resource::release_kind() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.Resource.kind)
  
  return kind_.ReleaseNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited());
}
void Resource::set_allocated_kind(::std::string* kind) {
  if (kind != NULL) {
    
  } else {
    
  }
  kind_.SetAllocatedNoArena(&::google::protobuf::internal::GetEmptyStringAlreadyInited(), kind);
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.Resource.kind)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ResourceAllocation_Entry::kResourceFieldNumber;
const int ResourceAllocation_Entry::kQuantityFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ResourceAllocation_Entry::ResourceAllocation_Entry()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ResourceAllocation.Entry)
}
ResourceAllocation_Entry::ResourceAllocation_Entry(const ResourceAllocation_Entry& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_resource()) {
    resource_ = new ::tensorflow::serving::Resource(*from.resource_);
  } else {
    resource_ = NULL;
  }
  quantity_ = from.quantity_;
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ResourceAllocation.Entry)
}

void ResourceAllocation_Entry::SharedCtor() {
  ::memset(&resource_, 0, reinterpret_cast<char*>(&quantity_) -
    reinterpret_cast<char*>(&resource_) + sizeof(quantity_));
  _cached_size_ = 0;
}

ResourceAllocation_Entry::~ResourceAllocation_Entry() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ResourceAllocation.Entry)
  SharedDtor();
}

void ResourceAllocation_Entry::SharedDtor() {
  if (this != internal_default_instance()) {
    delete resource_;
  }
}

void ResourceAllocation_Entry::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ResourceAllocation_Entry::descriptor() {
  protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::file_level_metadata[1].descriptor;
}

const ResourceAllocation_Entry& ResourceAllocation_Entry::default_instance() {
  protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::InitDefaults();
  return *internal_default_instance();
}

ResourceAllocation_Entry* ResourceAllocation_Entry::New(::google::protobuf::Arena* arena) const {
  ResourceAllocation_Entry* n = new ResourceAllocation_Entry;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ResourceAllocation_Entry::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ResourceAllocation.Entry)
  if (GetArenaNoVirtual() == NULL && resource_ != NULL) {
    delete resource_;
  }
  resource_ = NULL;
  quantity_ = GOOGLE_ULONGLONG(0);
}

bool ResourceAllocation_Entry::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ResourceAllocation.Entry)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // .tensorflow.serving.Resource resource = 1;
      case 1: {
        if (tag == 10u) {
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtual(
               input, mutable_resource()));
        } else {
          goto handle_unusual;
        }
        break;
      }

      // uint64 quantity = 2;
      case 2: {
        if (tag == 16u) {

          DO_((::google::protobuf::internal::WireFormatLite::ReadPrimitive<
                   ::google::protobuf::uint64, ::google::protobuf::internal::WireFormatLite::TYPE_UINT64>(
                 input, &quantity_)));
        } else {
          goto handle_unusual;
        }
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ResourceAllocation.Entry)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ResourceAllocation.Entry)
  return false;
#undef DO_
}

void ResourceAllocation_Entry::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ResourceAllocation.Entry)
  // .tensorflow.serving.Resource resource = 1;
  if (this->has_resource()) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, *this->resource_, output);
  }

  // uint64 quantity = 2;
  if (this->quantity() != 0) {
    ::google::protobuf::internal::WireFormatLite::WriteUInt64(2, this->quantity(), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ResourceAllocation.Entry)
}

::google::protobuf::uint8* ResourceAllocation_Entry::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ResourceAllocation.Entry)
  // .tensorflow.serving.Resource resource = 1;
  if (this->has_resource()) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, *this->resource_, false, target);
  }

  // uint64 quantity = 2;
  if (this->quantity() != 0) {
    target = ::google::protobuf::internal::WireFormatLite::WriteUInt64ToArray(2, this->quantity(), target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ResourceAllocation.Entry)
  return target;
}

size_t ResourceAllocation_Entry::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ResourceAllocation.Entry)
  size_t total_size = 0;

  // .tensorflow.serving.Resource resource = 1;
  if (this->has_resource()) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
        *this->resource_);
  }

  // uint64 quantity = 2;
  if (this->quantity() != 0) {
    total_size += 1 +
      ::google::protobuf::internal::WireFormatLite::UInt64Size(
        this->quantity());
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ResourceAllocation_Entry::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ResourceAllocation.Entry)
  GOOGLE_DCHECK_NE(&from, this);
  const ResourceAllocation_Entry* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const ResourceAllocation_Entry>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ResourceAllocation.Entry)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ResourceAllocation.Entry)
    MergeFrom(*source);
  }
}

void ResourceAllocation_Entry::MergeFrom(const ResourceAllocation_Entry& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ResourceAllocation.Entry)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  if (from.has_resource()) {
    mutable_resource()->::tensorflow::serving::Resource::MergeFrom(from.resource());
  }
  if (from.quantity() != 0) {
    set_quantity(from.quantity());
  }
}

void ResourceAllocation_Entry::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ResourceAllocation.Entry)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ResourceAllocation_Entry::CopyFrom(const ResourceAllocation_Entry& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ResourceAllocation.Entry)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ResourceAllocation_Entry::IsInitialized() const {
  return true;
}

void ResourceAllocation_Entry::Swap(ResourceAllocation_Entry* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ResourceAllocation_Entry::InternalSwap(ResourceAllocation_Entry* other) {
  std::swap(resource_, other->resource_);
  std::swap(quantity_, other->quantity_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ResourceAllocation_Entry::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::file_level_metadata[1];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ResourceAllocation_Entry

// .tensorflow.serving.Resource resource = 1;
bool ResourceAllocation_Entry::has_resource() const {
  return this != internal_default_instance() && resource_ != NULL;
}
void ResourceAllocation_Entry::clear_resource() {
  if (GetArenaNoVirtual() == NULL && resource_ != NULL) delete resource_;
  resource_ = NULL;
}
const ::tensorflow::serving::Resource& ResourceAllocation_Entry::resource() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ResourceAllocation.Entry.resource)
  return resource_ != NULL ? *resource_
                         : *::tensorflow::serving::Resource::internal_default_instance();
}
::tensorflow::serving::Resource* ResourceAllocation_Entry::mutable_resource() {
  
  if (resource_ == NULL) {
    resource_ = new ::tensorflow::serving::Resource;
  }
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ResourceAllocation.Entry.resource)
  return resource_;
}
::tensorflow::serving::Resource* ResourceAllocation_Entry::release_resource() {
  // @@protoc_insertion_point(field_release:tensorflow.serving.ResourceAllocation.Entry.resource)
  
  ::tensorflow::serving::Resource* temp = resource_;
  resource_ = NULL;
  return temp;
}
void ResourceAllocation_Entry::set_allocated_resource(::tensorflow::serving::Resource* resource) {
  delete resource_;
  resource_ = resource;
  if (resource) {
    
  } else {
    
  }
  // @@protoc_insertion_point(field_set_allocated:tensorflow.serving.ResourceAllocation.Entry.resource)
}

// uint64 quantity = 2;
void ResourceAllocation_Entry::clear_quantity() {
  quantity_ = GOOGLE_ULONGLONG(0);
}
::google::protobuf::uint64 ResourceAllocation_Entry::quantity() const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ResourceAllocation.Entry.quantity)
  return quantity_;
}
void ResourceAllocation_Entry::set_quantity(::google::protobuf::uint64 value) {
  
  quantity_ = value;
  // @@protoc_insertion_point(field_set:tensorflow.serving.ResourceAllocation.Entry.quantity)
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// ===================================================================

#if !defined(_MSC_VER) || _MSC_VER >= 1900
const int ResourceAllocation::kResourceQuantitiesFieldNumber;
#endif  // !defined(_MSC_VER) || _MSC_VER >= 1900

ResourceAllocation::ResourceAllocation()
  : ::google::protobuf::Message(), _internal_metadata_(NULL) {
  if (GOOGLE_PREDICT_TRUE(this != internal_default_instance())) {
    protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::InitDefaults();
  }
  SharedCtor();
  // @@protoc_insertion_point(constructor:tensorflow.serving.ResourceAllocation)
}
ResourceAllocation::ResourceAllocation(const ResourceAllocation& from)
  : ::google::protobuf::Message(),
      _internal_metadata_(NULL),
      resource_quantities_(from.resource_quantities_),
      _cached_size_(0) {
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:tensorflow.serving.ResourceAllocation)
}

void ResourceAllocation::SharedCtor() {
  _cached_size_ = 0;
}

ResourceAllocation::~ResourceAllocation() {
  // @@protoc_insertion_point(destructor:tensorflow.serving.ResourceAllocation)
  SharedDtor();
}

void ResourceAllocation::SharedDtor() {
}

void ResourceAllocation::SetCachedSize(int size) const {
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
}
const ::google::protobuf::Descriptor* ResourceAllocation::descriptor() {
  protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::file_level_metadata[2].descriptor;
}

const ResourceAllocation& ResourceAllocation::default_instance() {
  protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::InitDefaults();
  return *internal_default_instance();
}

ResourceAllocation* ResourceAllocation::New(::google::protobuf::Arena* arena) const {
  ResourceAllocation* n = new ResourceAllocation;
  if (arena != NULL) {
    arena->Own(n);
  }
  return n;
}

void ResourceAllocation::Clear() {
// @@protoc_insertion_point(message_clear_start:tensorflow.serving.ResourceAllocation)
  resource_quantities_.Clear();
}

bool ResourceAllocation::MergePartialFromCodedStream(
    ::google::protobuf::io::CodedInputStream* input) {
#define DO_(EXPRESSION) if (!GOOGLE_PREDICT_TRUE(EXPRESSION)) goto failure
  ::google::protobuf::uint32 tag;
  // @@protoc_insertion_point(parse_start:tensorflow.serving.ResourceAllocation)
  for (;;) {
    ::std::pair< ::google::protobuf::uint32, bool> p = input->ReadTagWithCutoffNoLastTag(127u);
    tag = p.first;
    if (!p.second) goto handle_unusual;
    switch (::google::protobuf::internal::WireFormatLite::GetTagFieldNumber(tag)) {
      // repeated .tensorflow.serving.ResourceAllocation.Entry resource_quantities = 1;
      case 1: {
        if (tag == 10u) {
          DO_(input->IncrementRecursionDepth());
          DO_(::google::protobuf::internal::WireFormatLite::ReadMessageNoVirtualNoRecursionDepth(
                input, add_resource_quantities()));
        } else {
          goto handle_unusual;
        }
        input->UnsafeDecrementRecursionDepth();
        break;
      }

      default: {
      handle_unusual:
        if (tag == 0 ||
            ::google::protobuf::internal::WireFormatLite::GetTagWireType(tag) ==
            ::google::protobuf::internal::WireFormatLite::WIRETYPE_END_GROUP) {
          goto success;
        }
        DO_(::google::protobuf::internal::WireFormatLite::SkipField(input, tag));
        break;
      }
    }
  }
success:
  // @@protoc_insertion_point(parse_success:tensorflow.serving.ResourceAllocation)
  return true;
failure:
  // @@protoc_insertion_point(parse_failure:tensorflow.serving.ResourceAllocation)
  return false;
#undef DO_
}

void ResourceAllocation::SerializeWithCachedSizes(
    ::google::protobuf::io::CodedOutputStream* output) const {
  // @@protoc_insertion_point(serialize_start:tensorflow.serving.ResourceAllocation)
  // repeated .tensorflow.serving.ResourceAllocation.Entry resource_quantities = 1;
  for (unsigned int i = 0, n = this->resource_quantities_size(); i < n; i++) {
    ::google::protobuf::internal::WireFormatLite::WriteMessageMaybeToArray(
      1, this->resource_quantities(i), output);
  }

  // @@protoc_insertion_point(serialize_end:tensorflow.serving.ResourceAllocation)
}

::google::protobuf::uint8* ResourceAllocation::InternalSerializeWithCachedSizesToArray(
    bool deterministic, ::google::protobuf::uint8* target) const {
  (void)deterministic;  // Unused
  // @@protoc_insertion_point(serialize_to_array_start:tensorflow.serving.ResourceAllocation)
  // repeated .tensorflow.serving.ResourceAllocation.Entry resource_quantities = 1;
  for (unsigned int i = 0, n = this->resource_quantities_size(); i < n; i++) {
    target = ::google::protobuf::internal::WireFormatLite::
      InternalWriteMessageNoVirtualToArray(
        1, this->resource_quantities(i), false, target);
  }

  // @@protoc_insertion_point(serialize_to_array_end:tensorflow.serving.ResourceAllocation)
  return target;
}

size_t ResourceAllocation::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:tensorflow.serving.ResourceAllocation)
  size_t total_size = 0;

  // repeated .tensorflow.serving.ResourceAllocation.Entry resource_quantities = 1;
  {
    unsigned int count = this->resource_quantities_size();
    total_size += 1UL * count;
    for (unsigned int i = 0; i < count; i++) {
      total_size +=
        ::google::protobuf::internal::WireFormatLite::MessageSizeNoVirtual(
          this->resource_quantities(i));
    }
  }

  int cached_size = ::google::protobuf::internal::ToCachedSize(total_size);
  GOOGLE_SAFE_CONCURRENT_WRITES_BEGIN();
  _cached_size_ = cached_size;
  GOOGLE_SAFE_CONCURRENT_WRITES_END();
  return total_size;
}

void ResourceAllocation::MergeFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_merge_from_start:tensorflow.serving.ResourceAllocation)
  GOOGLE_DCHECK_NE(&from, this);
  const ResourceAllocation* source =
      ::google::protobuf::internal::DynamicCastToGenerated<const ResourceAllocation>(
          &from);
  if (source == NULL) {
  // @@protoc_insertion_point(generalized_merge_from_cast_fail:tensorflow.serving.ResourceAllocation)
    ::google::protobuf::internal::ReflectionOps::Merge(from, this);
  } else {
  // @@protoc_insertion_point(generalized_merge_from_cast_success:tensorflow.serving.ResourceAllocation)
    MergeFrom(*source);
  }
}

void ResourceAllocation::MergeFrom(const ResourceAllocation& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:tensorflow.serving.ResourceAllocation)
  GOOGLE_DCHECK_NE(&from, this);
  _internal_metadata_.MergeFrom(from._internal_metadata_);
  resource_quantities_.MergeFrom(from.resource_quantities_);
}

void ResourceAllocation::CopyFrom(const ::google::protobuf::Message& from) {
// @@protoc_insertion_point(generalized_copy_from_start:tensorflow.serving.ResourceAllocation)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

void ResourceAllocation::CopyFrom(const ResourceAllocation& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:tensorflow.serving.ResourceAllocation)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool ResourceAllocation::IsInitialized() const {
  return true;
}

void ResourceAllocation::Swap(ResourceAllocation* other) {
  if (other == this) return;
  InternalSwap(other);
}
void ResourceAllocation::InternalSwap(ResourceAllocation* other) {
  resource_quantities_.UnsafeArenaSwap(&other->resource_quantities_);
  std::swap(_cached_size_, other->_cached_size_);
}

::google::protobuf::Metadata ResourceAllocation::GetMetadata() const {
  protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::protobuf_AssignDescriptorsOnce();
  return protobuf_tensorflow_5fserving_2fresources_2fresources_2eproto::file_level_metadata[2];
}

#if PROTOBUF_INLINE_NOT_IN_HEADERS
// ResourceAllocation

// repeated .tensorflow.serving.ResourceAllocation.Entry resource_quantities = 1;
int ResourceAllocation::resource_quantities_size() const {
  return resource_quantities_.size();
}
void ResourceAllocation::clear_resource_quantities() {
  resource_quantities_.Clear();
}
const ::tensorflow::serving::ResourceAllocation_Entry& ResourceAllocation::resource_quantities(int index) const {
  // @@protoc_insertion_point(field_get:tensorflow.serving.ResourceAllocation.resource_quantities)
  return resource_quantities_.Get(index);
}
::tensorflow::serving::ResourceAllocation_Entry* ResourceAllocation::mutable_resource_quantities(int index) {
  // @@protoc_insertion_point(field_mutable:tensorflow.serving.ResourceAllocation.resource_quantities)
  return resource_quantities_.Mutable(index);
}
::tensorflow::serving::ResourceAllocation_Entry* ResourceAllocation::add_resource_quantities() {
  // @@protoc_insertion_point(field_add:tensorflow.serving.ResourceAllocation.resource_quantities)
  return resource_quantities_.Add();
}
::google::protobuf::RepeatedPtrField< ::tensorflow::serving::ResourceAllocation_Entry >*
ResourceAllocation::mutable_resource_quantities() {
  // @@protoc_insertion_point(field_mutable_list:tensorflow.serving.ResourceAllocation.resource_quantities)
  return &resource_quantities_;
}
const ::google::protobuf::RepeatedPtrField< ::tensorflow::serving::ResourceAllocation_Entry >&
ResourceAllocation::resource_quantities() const {
  // @@protoc_insertion_point(field_list:tensorflow.serving.ResourceAllocation.resource_quantities)
  return resource_quantities_;
}

#endif  // PROTOBUF_INLINE_NOT_IN_HEADERS

// @@protoc_insertion_point(namespace_scope)

}  // namespace serving
}  // namespace tensorflow

// @@protoc_insertion_point(global_scope)
