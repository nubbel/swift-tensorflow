# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow_serving/config/model_server_config.proto

require 'google/protobuf'

require 'google/protobuf/any_pb'
require 'tensorflow_serving/config/logging_config_pb'
require 'tensorflow_serving/sources/storage_path/file_system_storage_path_source_pb'
Google::Protobuf::DescriptorPool.generated_pool.build do
  add_message "tensorflow.serving.ModelConfig" do
    optional :name, :string, 1
    optional :base_path, :string, 2
    optional :model_type, :enum, 3, "tensorflow.serving.ModelType"
    optional :model_platform, :string, 4
    optional :version_policy, :enum, 5, "tensorflow.serving.FileSystemStoragePathSourceConfig.VersionPolicy"
    optional :logging_config, :message, 6, "tensorflow.serving.LoggingConfig"
  end
  add_message "tensorflow.serving.ModelConfigList" do
    repeated :config, :message, 1, "tensorflow.serving.ModelConfig"
  end
  add_message "tensorflow.serving.ModelServerConfig" do
    oneof :config do
      optional :model_config_list, :message, 1, "tensorflow.serving.ModelConfigList"
      optional :custom_model_config, :message, 2, "google.protobuf.Any"
    end
  end
  add_enum "tensorflow.serving.ModelType" do
    value :MODEL_TYPE_UNSPECIFIED, 0
    value :TENSORFLOW, 1
    value :OTHER, 2
  end
end

module Tensorflow
  module Serving
    ModelConfig = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.serving.ModelConfig").msgclass
    ModelConfigList = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.serving.ModelConfigList").msgclass
    ModelServerConfig = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.serving.ModelServerConfig").msgclass
    ModelType = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.serving.ModelType").enummodule
  end
end
