# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow_serving/servables/tensorflow/session_bundle_config.proto

require 'google/protobuf'

require 'google/protobuf/wrappers_pb'
require 'tensorflow/core/protobuf/config_pb'
require 'tensorflow/core/protobuf/named_tensor_pb'
Google::Protobuf::DescriptorPool.generated_pool.build do
  add_message "tensorflow.serving.SessionBundleConfig" do
    optional :session_target, :string, 1
    optional :session_config, :message, 2, "tensorflow.ConfigProto"
    optional :batching_parameters, :message, 3, "tensorflow.serving.BatchingParameters"
    optional :session_run_load_threadpool_index, :message, 4, "google.protobuf.Int32Value"
    repeated :experimental_fixed_input_tensors, :message, 778, "tensorflow.NamedTensorProto"
  end
  add_message "tensorflow.serving.BatchingParameters" do
    optional :max_batch_size, :message, 1, "google.protobuf.Int64Value"
    optional :batch_timeout_micros, :message, 2, "google.protobuf.Int64Value"
    optional :max_enqueued_batches, :message, 3, "google.protobuf.Int64Value"
    optional :num_batch_threads, :message, 4, "google.protobuf.Int64Value"
    optional :thread_pool_name, :message, 5, "google.protobuf.StringValue"
    repeated :allowed_batch_sizes, :int64, 6
  end
end

module Tensorflow
  module Serving
    SessionBundleConfig = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.serving.SessionBundleConfig").msgclass
    BatchingParameters = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.serving.BatchingParameters").msgclass
  end
end
