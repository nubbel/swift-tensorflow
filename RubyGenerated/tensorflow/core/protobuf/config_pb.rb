# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: tensorflow/core/protobuf/config.proto

require 'google/protobuf'

require 'tensorflow/core/framework/cost_graph_pb'
require 'tensorflow/core/framework/graph_pb'
require 'tensorflow/core/framework/step_stats_pb'
require 'tensorflow/core/protobuf/debug_pb'
require 'tensorflow/core/protobuf/rewriter_config_pb'
Google::Protobuf::DescriptorPool.generated_pool.build do
  add_message "tensorflow.GPUOptions" do
    optional :per_process_gpu_memory_fraction, :double, 1
    optional :allocator_type, :string, 2
    optional :deferred_deletion_bytes, :int64, 3
    optional :allow_growth, :bool, 4
    optional :visible_device_list, :string, 5
    optional :polling_active_delay_usecs, :int32, 6
    optional :polling_inactive_delay_msecs, :int32, 7
    optional :force_gpu_compatible, :bool, 8
  end
  add_message "tensorflow.OptimizerOptions" do
    optional :do_common_subexpression_elimination, :bool, 1
    optional :do_constant_folding, :bool, 2
    optional :do_function_inlining, :bool, 4
    optional :opt_level, :enum, 3, "tensorflow.OptimizerOptions.Level"
    optional :global_jit_level, :enum, 5, "tensorflow.OptimizerOptions.GlobalJitLevel"
  end
  add_enum "tensorflow.OptimizerOptions.Level" do
    value :L1, 0
    value :L0, -1
  end
  add_enum "tensorflow.OptimizerOptions.GlobalJitLevel" do
    value :DEFAULT, 0
    value :OFF, -1
    value :ON_1, 1
    value :ON_2, 2
  end
  add_message "tensorflow.GraphOptions" do
    optional :enable_recv_scheduling, :bool, 2
    optional :optimizer_options, :message, 3, "tensorflow.OptimizerOptions"
    optional :build_cost_model, :int64, 4
    optional :build_cost_model_after, :int64, 9
    optional :infer_shapes, :bool, 5
    optional :place_pruned_graph, :bool, 6
    optional :enable_bfloat16_sendrecv, :bool, 7
    optional :timeline_step, :int32, 8
    optional :rewrite_options, :message, 10, "tensorflow.RewriterConfig"
  end
  add_message "tensorflow.ThreadPoolOptionProto" do
    optional :num_threads, :int32, 1
  end
  add_message "tensorflow.RPCOptions" do
    optional :use_rpc_for_inprocess_master, :bool, 1
  end
  add_message "tensorflow.ConfigProto" do
    map :device_count, :string, :int32, 1
    optional :intra_op_parallelism_threads, :int32, 2
    optional :inter_op_parallelism_threads, :int32, 5
    optional :use_per_session_threads, :bool, 9
    repeated :session_inter_op_thread_pool, :message, 12, "tensorflow.ThreadPoolOptionProto"
    optional :placement_period, :int32, 3
    repeated :device_filters, :string, 4
    optional :gpu_options, :message, 6, "tensorflow.GPUOptions"
    optional :allow_soft_placement, :bool, 7
    optional :log_device_placement, :bool, 8
    optional :graph_options, :message, 10, "tensorflow.GraphOptions"
    optional :operation_timeout_in_ms, :int64, 11
    optional :rpc_options, :message, 13, "tensorflow.RPCOptions"
  end
  add_message "tensorflow.RunOptions" do
    optional :trace_level, :enum, 1, "tensorflow.RunOptions.TraceLevel"
    optional :timeout_in_ms, :int64, 2
    optional :inter_op_thread_pool, :int32, 3
    optional :output_partition_graphs, :bool, 5
    optional :debug_options, :message, 6, "tensorflow.DebugOptions"
  end
  add_enum "tensorflow.RunOptions.TraceLevel" do
    value :NO_TRACE, 0
    value :SOFTWARE_TRACE, 1
    value :HARDWARE_TRACE, 2
    value :FULL_TRACE, 3
  end
  add_message "tensorflow.RunMetadata" do
    optional :step_stats, :message, 1, "tensorflow.StepStats"
    optional :cost_graph, :message, 2, "tensorflow.CostGraphDef"
    repeated :partition_graphs, :message, 3, "tensorflow.GraphDef"
  end
end

module Tensorflow
  GPUOptions = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.GPUOptions").msgclass
  OptimizerOptions = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.OptimizerOptions").msgclass
  OptimizerOptions::Level = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.OptimizerOptions.Level").enummodule
  OptimizerOptions::GlobalJitLevel = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.OptimizerOptions.GlobalJitLevel").enummodule
  GraphOptions = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.GraphOptions").msgclass
  ThreadPoolOptionProto = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.ThreadPoolOptionProto").msgclass
  RPCOptions = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RPCOptions").msgclass
  ConfigProto = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.ConfigProto").msgclass
  RunOptions = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunOptions").msgclass
  RunOptions::TraceLevel = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunOptions.TraceLevel").enummodule
  RunMetadata = Google::Protobuf::DescriptorPool.generated_pool.lookup("tensorflow.RunMetadata").msgclass
end
